{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55bbf6c0",
   "metadata": {},
   "source": [
    "### Analysis of Kaggle Titanic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785b0e05",
   "metadata": {},
   "source": [
    "Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "d5a12aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as ex\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn.preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414782d8",
   "metadata": {},
   "source": [
    "Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "0e8b44d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"C:\\\\Users\\\\User\\\\Downloads\\\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "b1e621f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"C:\\\\Users\\\\User\\\\Downloads\\\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "b65d5062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "a0319439",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6be102f",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "62824aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "5f676114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "4d19ebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_train.iloc[:, 2:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "b6bd71c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass                                               Name     Sex   Age  \\\n",
       "0         3                            Braund, Mr. Owen Harris    male  22.0   \n",
       "1         1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "2         3                             Heikkinen, Miss. Laina  female  26.0   \n",
       "3         1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "4         3                           Allen, Mr. William Henry    male  35.0   \n",
       "..      ...                                                ...     ...   ...   \n",
       "886       2                              Montvila, Rev. Juozas    male  27.0   \n",
       "887       1                       Graham, Miss. Margaret Edith  female  19.0   \n",
       "888       3           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN   \n",
       "889       1                              Behr, Mr. Karl Howell    male  26.0   \n",
       "890       3                                Dooley, Mr. Patrick    male  32.0   \n",
       "\n",
       "     SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0        1      0         A/5 21171   7.2500   NaN        S  \n",
       "1        1      0          PC 17599  71.2833   C85        C  \n",
       "2        0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        1      0            113803  53.1000  C123        S  \n",
       "4        0      0            373450   8.0500   NaN        S  \n",
       "..     ...    ...               ...      ...   ...      ...  \n",
       "886      0      0            211536  13.0000   NaN        S  \n",
       "887      0      0            112053  30.0000   B42        S  \n",
       "888      1      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0      0            111369  30.0000  C148        C  \n",
       "890      0      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 10 columns]"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "60b43fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.iloc[:, 1:2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "51b89a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "30cd5954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 1)"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "8acd1693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "5d10a662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0           549\n",
       "1           342\n",
       "dtype: int64"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "6f2409cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0           0.616162\n",
       "1           0.383838\n",
       "dtype: float64"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "18200114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Survived'>"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y.value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "4ea0d4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "ad585202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "696ecfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Survived'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "44b240b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass                                               Name     Sex   Age  \\\n",
       "0         3                            Braund, Mr. Owen Harris    male  22.0   \n",
       "1         1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "2         3                             Heikkinen, Miss. Laina  female  26.0   \n",
       "3         1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "4         3                           Allen, Mr. William Henry    male  35.0   \n",
       "..      ...                                                ...     ...   ...   \n",
       "886       2                              Montvila, Rev. Juozas    male  27.0   \n",
       "887       1                       Graham, Miss. Margaret Edith  female  19.0   \n",
       "888       3           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN   \n",
       "889       1                              Behr, Mr. Karl Howell    male  26.0   \n",
       "890       3                                Dooley, Mr. Patrick    male  32.0   \n",
       "\n",
       "     SibSp  Parch            Ticket     Fare Cabin Embarked  Survived  \n",
       "0        1      0         A/5 21171   7.2500   NaN        S         0  \n",
       "1        1      0          PC 17599  71.2833   C85        C         1  \n",
       "2        0      0  STON/O2. 3101282   7.9250   NaN        S         1  \n",
       "3        1      0            113803  53.1000  C123        S         1  \n",
       "4        0      0            373450   8.0500   NaN        S         0  \n",
       "..     ...    ...               ...      ...   ...      ...       ...  \n",
       "886      0      0            211536  13.0000   NaN        S         0  \n",
       "887      0      0            112053  30.0000   B42        S         1  \n",
       "888      1      2        W./C. 6607  23.4500   NaN        S         0  \n",
       "889      0      0            111369  30.0000  C148        C         1  \n",
       "890      0      0            370376   7.7500   NaN        Q         0  \n",
       "\n",
       "[891 rows x 11 columns]"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "ad08359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Name' , axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "d86235ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test.drop('Name', axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "d347e91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Ticket', axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "67185a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass     Sex   Age  SibSp  Parch     Fare Cabin Embarked  Survived\n",
       "0         3    male  22.0      1      0   7.2500   NaN        S         0\n",
       "1         1  female  38.0      1      0  71.2833   C85        C         1\n",
       "2         3  female  26.0      0      0   7.9250   NaN        S         1\n",
       "3         1  female  35.0      1      0  53.1000  C123        S         1\n",
       "4         3    male  35.0      0      0   8.0500   NaN        S         0\n",
       "..      ...     ...   ...    ...    ...      ...   ...      ...       ...\n",
       "886       2    male  27.0      0      0  13.0000   NaN        S         0\n",
       "887       1  female  19.0      0      0  30.0000   B42        S         1\n",
       "888       3  female   NaN      1      2  23.4500   NaN        S         0\n",
       "889       1    male  26.0      0      0  30.0000  C148        C         1\n",
       "890       3    male  32.0      0      0   7.7500   NaN        Q         0\n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "12083ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Cabin', axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "8f01269a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass     Sex   Age  SibSp  Parch     Fare Embarked  Survived\n",
       "0         3    male  22.0      1      0   7.2500        S         0\n",
       "1         1  female  38.0      1      0  71.2833        C         1\n",
       "2         3  female  26.0      0      0   7.9250        S         1\n",
       "3         1  female  35.0      1      0  53.1000        S         1\n",
       "4         3    male  35.0      0      0   8.0500        S         0\n",
       "..      ...     ...   ...    ...    ...      ...      ...       ...\n",
       "886       2    male  27.0      0      0  13.0000        S         0\n",
       "887       1  female  19.0      0      0  30.0000        S         1\n",
       "888       3  female   NaN      1      2  23.4500        S         0\n",
       "889       1    male  26.0      0      0  30.0000        C         1\n",
       "890       3    male  32.0      0      0   7.7500        Q         0\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "32b58878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "736b618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "02a905bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_label = label_encoder.fit_transform(df['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "80185588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass   Age  SibSp  Parch     Fare Embarked  Survived\n",
       "0         3  22.0      1      0   7.2500        S         0\n",
       "1         1  38.0      1      0  71.2833        C         1\n",
       "2         3  26.0      0      0   7.9250        S         1\n",
       "3         1  35.0      1      0  53.1000        S         1\n",
       "4         3  35.0      0      0   8.0500        S         0\n",
       "..      ...   ...    ...    ...      ...      ...       ...\n",
       "886       2  27.0      0      0  13.0000        S         0\n",
       "887       1  19.0      0      0  30.0000        S         1\n",
       "888       3   NaN      1      2  23.4500        S         0\n",
       "889       1  26.0      0      0  30.0000        C         1\n",
       "890       3  32.0      0      0   7.7500        Q         0\n",
       "\n",
       "[891 rows x 7 columns]"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('Sex', axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "8ff8fb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sex'] = sex_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "b77f5a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex   Age  SibSp  Parch     Fare Embarked  Survived\n",
       "0         3    1  22.0      1      0   7.2500        S         0\n",
       "1         1    0  38.0      1      0  71.2833        C         1\n",
       "2         3    0  26.0      0      0   7.9250        S         1\n",
       "3         1    0  35.0      1      0  53.1000        S         1\n",
       "4         3    1  35.0      0      0   8.0500        S         0\n",
       "..      ...  ...   ...    ...    ...      ...      ...       ...\n",
       "886       2    1  27.0      0      0  13.0000        S         0\n",
       "887       1    0  19.0      0      0  30.0000        S         1\n",
       "888       3    0   NaN      1      2  23.4500        S         0\n",
       "889       1    1  26.0      0      0  30.0000        C         1\n",
       "890       3    1  32.0      0      0   7.7500        Q         0\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "c62e1464",
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_label = label_encoder.fit_transform(df['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "00132f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex   Age  SibSp  Parch     Fare  Survived\n",
       "0         3    1  22.0      1      0   7.2500         0\n",
       "1         1    0  38.0      1      0  71.2833         1\n",
       "2         3    0  26.0      0      0   7.9250         1\n",
       "3         1    0  35.0      1      0  53.1000         1\n",
       "4         3    1  35.0      0      0   8.0500         0\n",
       "..      ...  ...   ...    ...    ...      ...       ...\n",
       "886       2    1  27.0      0      0  13.0000         0\n",
       "887       1    0  19.0      0      0  30.0000         1\n",
       "888       3    0   NaN      1      2  23.4500         0\n",
       "889       1    1  26.0      0      0  30.0000         1\n",
       "890       3    1  32.0      0      0   7.7500         0\n",
       "\n",
       "[891 rows x 7 columns]"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('Embarked', axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "732aff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Embarked'] = embarked_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "3309ad2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  Survived\n",
       "0         3    1  22.0      1      0   7.2500         2         0\n",
       "1         1    0  38.0      1      0  71.2833         0         1\n",
       "2         3    0  26.0      0      0   7.9250         2         1\n",
       "3         1    0  35.0      1      0  53.1000         2         1\n",
       "4         3    1  35.0      0      0   8.0500         2         0\n",
       "..      ...  ...   ...    ...    ...      ...       ...       ...\n",
       "886       2    1  27.0      0      0  13.0000         2         0\n",
       "887       1    0  19.0      0      0  30.0000         2         1\n",
       "888       3    0   NaN      1      2  23.4500         2         0\n",
       "889       1    1  26.0      0      0  30.0000         0         1\n",
       "890       3    1  32.0      0      0   7.7500         1         0\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "55b1de5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "corrmat = df.corr()\n",
    "hm = sns.heatmap(corrmat, \n",
    "                 vmin=-1, vmax=1, annot=True)\n",
    "hm.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ccc20b",
   "metadata": {},
   "source": [
    "Here its observed that the relationship between Survived and Fare is high and the worst relationship is with Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "94da6878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "sns.scatterplot(x=\"Age\", y=\"Fare\", hue=\"Survived\", data=df, palette=\"Dark2\", s=80)\n",
    "plt.title(\"Relationship between Age, Sex and Survived\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a82800",
   "metadata": {},
   "source": [
    "It can be seen that people with higher fare types were more likely to survive, also irrespective of fare, at ages lower than 10 there were more fatalaties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "eafcaaec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "sns.boxplot(x=df[\"Age\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "acf762f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  Survived\n",
       "0         3    1  22.0      1      0   7.2500         2         0\n",
       "1         1    0  38.0      1      0  71.2833         0         1\n",
       "2         3    0  26.0      0      0   7.9250         2         1\n",
       "3         1    0  35.0      1      0  53.1000         2         1\n",
       "4         3    1  35.0      0      0   8.0500         2         0\n",
       "..      ...  ...   ...    ...    ...      ...       ...       ...\n",
       "886       2    1  27.0      0      0  13.0000         2         0\n",
       "887       1    0  19.0      0      0  30.0000         2         1\n",
       "888       3    0   NaN      1      2  23.4500         2         0\n",
       "889       1    1  26.0      0      0  30.0000         0         1\n",
       "890       3    1  32.0      0      0   7.7500         1         0\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "e097038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "f85ea8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 7)"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "9b3525ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 1)"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "d415548f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Fare          0\n",
       "Embarked      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "c9b66474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "80d452d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "eb3644e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "simp_imputer = SimpleImputer(missing_values=np.nan, strategy='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "f76ae2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_imputer = IterativeImputer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "590352ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_imputer = iter_imputer.fit(X[['Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "5f2f91fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Age'] = iter_imputer.transform(X[['Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "eb558571",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass      0\n",
       "Sex         0\n",
       "Age         0\n",
       "SibSp       0\n",
       "Parch       0\n",
       "Fare        0\n",
       "Embarked    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "c93901cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex        Age  SibSp  Parch     Fare  Embarked\n",
       "0         3    1  22.000000      1      0   7.2500         2\n",
       "1         1    0  38.000000      1      0  71.2833         0\n",
       "2         3    0  26.000000      0      0   7.9250         2\n",
       "3         1    0  35.000000      1      0  53.1000         2\n",
       "4         3    1  35.000000      0      0   8.0500         2\n",
       "..      ...  ...        ...    ...    ...      ...       ...\n",
       "886       2    1  27.000000      0      0  13.0000         2\n",
       "887       1    0  19.000000      0      0  30.0000         2\n",
       "888       3    0  29.699118      1      2  23.4500         2\n",
       "889       1    1  26.000000      0      0  30.0000         0\n",
       "890       3    1  32.000000      0      0   7.7500         1\n",
       "\n",
       "[891 rows x 7 columns]"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "c57b924c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 7)"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "313e9c96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 1)"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "6528334b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass     Sex   Age  SibSp  Parch              Ticket  \\\n",
       "0            892       3    male  34.5      0      0              330911   \n",
       "1            893       3  female  47.0      1      0              363272   \n",
       "2            894       2    male  62.0      0      0              240276   \n",
       "3            895       3    male  27.0      0      0              315154   \n",
       "4            896       3  female  22.0      1      1             3101298   \n",
       "..           ...     ...     ...   ...    ...    ...                 ...   \n",
       "413         1305       3    male   NaN      0      0           A.5. 3236   \n",
       "414         1306       1  female  39.0      0      0            PC 17758   \n",
       "415         1307       3    male  38.5      0      0  SOTON/O.Q. 3101262   \n",
       "416         1308       3    male   NaN      0      0              359309   \n",
       "417         1309       3    male   NaN      1      1                2668   \n",
       "\n",
       "         Fare Cabin Embarked  \n",
       "0      7.8292   NaN        Q  \n",
       "1      7.0000   NaN        S  \n",
       "2      9.6875   NaN        Q  \n",
       "3      8.6625   NaN        S  \n",
       "4     12.2875   NaN        S  \n",
       "..        ...   ...      ...  \n",
       "413    8.0500   NaN        S  \n",
       "414  108.9000  C105        C  \n",
       "415    7.2500   NaN        S  \n",
       "416    8.0500   NaN        S  \n",
       "417   22.3583   NaN        C  \n",
       "\n",
       "[418 rows x 10 columns]"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "988e8703",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_label_test = label_encoder.fit_transform(data_test['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "4aee233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_label_test = label_encoder.fit_transform(data_test['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "dcf6e089",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['Embarked'] = embarked_label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "182197f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['Sex'] = sex_label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "258857ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test.drop('Cabin', axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "e133a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test.drop('Ticket', axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "b06830fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass  Sex   Age  SibSp  Parch      Fare Embarked\n",
       "0            892       3    1  34.5      0      0    7.8292        Q\n",
       "1            893       3    0  47.0      1      0    7.0000        S\n",
       "2            894       2    1  62.0      0      0    9.6875        Q\n",
       "3            895       3    1  27.0      0      0    8.6625        S\n",
       "4            896       3    0  22.0      1      1   12.2875        S\n",
       "..           ...     ...  ...   ...    ...    ...       ...      ...\n",
       "413         1305       3    1   NaN      0      0    8.0500        S\n",
       "414         1306       1    0  39.0      0      0  108.9000        C\n",
       "415         1307       3    1  38.5      0      0    7.2500        S\n",
       "416         1308       3    1   NaN      0      0    8.0500        S\n",
       "417         1309       3    1   NaN      1      1   22.3583        C\n",
       "\n",
       "[418 rows x 8 columns]"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "3c37e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_imputer = iter_imputer.fit(data_test[['Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "84fcd76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_imputer_fare = iter_imputer.fit(data_test[['Fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "626b0104",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['Age'] = iter_imputer.transform(data_test[['Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "50cb7812",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['Fare'] = iter_imputer_fare.transform(data_test[['Fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "1a0858a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Pclass         0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Fare           0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "825485d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data_test.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61833744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "e2695033",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 7)"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e338109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "13f56329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 7)"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "f9654225",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 1)"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0d75b7",
   "metadata": {},
   "source": [
    "Making a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "552c2bb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [891, 418]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20748/1960131892.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mpredicted_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mf1_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mf1scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1134\u001b[0m     \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.66666667\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m        \u001b[1;33m,\u001b[0m \u001b[1;36m0.66666667\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \"\"\"\n\u001b[1;32m-> 1136\u001b[1;33m     return fbeta_score(\n\u001b[0m\u001b[0;32m   1137\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1275\u001b[0m     \"\"\"\n\u001b[0;32m   1276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1277\u001b[1;33m     _, _, f, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[0;32m   1278\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1562\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1563\u001b[1;33m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1565\u001b[0m     \u001b[1;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1362\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"average has to be one of \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1364\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1365\u001b[0m     \u001b[1;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m     \u001b[1;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \"\"\"\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y_true\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y_pred\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    385\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    388\u001b[0m             \u001b[1;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m             \u001b[1;33m%\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [891, 418]"
     ]
    }
   ],
   "source": [
    "models = [LogisticRegression(random_state=1), \n",
    "          RandomForestClassifier(random_state=1),\n",
    "          KNeighborsClassifier(n_neighbors = 5), \n",
    "          SVC(random_state=1), \n",
    "          SGDClassifier(), \n",
    "          DecisionTreeClassifier()]\n",
    "results = []\n",
    "f1scores = []\n",
    "for m in models:\n",
    "    pipeline = Pipeline([('impute', imputer),('scale', StandardScaler()), ('model', m)])\n",
    "#     cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "#     scores = cross_val_score(pipeline, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    pipeline.fit(X_train, y_train.values.ravel())\n",
    "    scores = pipeline.score(X_test, y_test)\n",
    "    predicted_val = pipeline.predict(X_test)\n",
    "    results.append(scores)\n",
    "    f1scores.append(f1_scores)\n",
    "for model, accuracy, f1 in zip(models, results, f1scores):\n",
    "    print(f\"Model: {model} >> Accuracy: {round(np.mean(accuracy), 4)}   |  F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed566bb9",
   "metadata": {},
   "source": [
    "Hyprerparameter tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "7a7ca93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lr = {'penalty':['l1','l2','elasticnet','none'], \n",
    "                 'max_iter':[100,500,1000], \n",
    "                 'solver':['newton-cg','lbfgs','liblinear','sag','saga']}\n",
    "param_grid_rf = {'criterion':['gini','entropy','log_loss'], \n",
    "                 'min_samples_split':[2,4,8]}\n",
    "k_range = list(range(1, 31))\n",
    "\n",
    "param_grid_knn = param_grid = dict(n_neighbors=k_range)\n",
    "param_grid_svc= {'C': [0.1,1, 10, 100, 1000], \n",
    "                 'gamma': [1,0.1,0.01,0.001,0.0001], \n",
    "                 'kernel': ['rbf']}\n",
    "param_grid_sgd= {'loss':['hinge','log_loss','loss','modified_huber','squared_hinge','perceptron'], \n",
    "                 'penalty':['l2','l1','elasticnet'], \n",
    "                 'max_iter':[5,50,100,500,1000]}\n",
    "param_grid_dt = {'max_depth':[10,20,30,40,50],\n",
    "                 'criterion':['gini','entropy','log_loss']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "1b7a819b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "[CV 1/5] END max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_iter=100, penalty=l1, solver=liblinear;, score=0.724 total time=   0.0s\n",
      "[CV 2/5] END max_iter=100, penalty=l1, solver=liblinear;, score=0.791 total time=   0.0s\n",
      "[CV 3/5] END max_iter=100, penalty=l1, solver=liblinear;, score=0.888 total time=   0.0s\n",
      "[CV 4/5] END max_iter=100, penalty=l1, solver=liblinear;, score=0.827 total time=   0.0s\n",
      "[CV 5/5] END max_iter=100, penalty=l1, solver=liblinear;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END max_iter=100, penalty=l1, solver=saga;, score=0.724 total time=   0.0s\n",
      "[CV 2/5] END max_iter=100, penalty=l1, solver=saga;, score=0.649 total time=   0.0s\n",
      "[CV 3/5] END max_iter=100, penalty=l1, solver=saga;, score=0.724 total time=   0.0s\n",
      "[CV 4/5] END max_iter=100, penalty=l1, solver=saga;, score=0.677 total time=   0.0s\n",
      "[CV 5/5] END max_iter=100, penalty=l1, solver=saga;, score=0.714 total time=   0.0s\n",
      "[CV 1/5] END max_iter=100, penalty=l2, solver=newton-cg;, score=0.731 total time=   0.0s\n",
      "[CV 2/5] END max_iter=100, penalty=l2, solver=newton-cg;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END max_iter=100, penalty=l2, solver=newton-cg;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END max_iter=100, penalty=l2, solver=newton-cg;, score=0.827 total time=   0.0s\n",
      "[CV 5/5] END max_iter=100, penalty=l2, solver=newton-cg;, score=0.782 total time=   0.0s\n",
      "[CV 1/5] END max_iter=100, penalty=l2, solver=lbfgs;, score=0.731 total time=   0.0s\n",
      "[CV 2/5] END max_iter=100, penalty=l2, solver=lbfgs;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END max_iter=100, penalty=l2, solver=lbfgs;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END max_iter=100, penalty=l2, solver=lbfgs;, score=0.827 total time=   0.0s\n",
      "[CV 5/5] END max_iter=100, penalty=l2, solver=lbfgs;, score=0.782 total time=   0.0s\n",
      "[CV 1/5] END max_iter=100, penalty=l2, solver=liblinear;, score=0.724 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END max_iter=100, penalty=l2, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 3/5] END max_iter=100, penalty=l2, solver=liblinear;, score=0.896 total time=   0.0s\n",
      "[CV 4/5] END max_iter=100, penalty=l2, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 5/5] END max_iter=100, penalty=l2, solver=liblinear;, score=0.789 total time=   0.0s\n",
      "[CV 1/5] END max_iter=100, penalty=l2, solver=sag;, score=0.724 total time=   0.0s\n",
      "[CV 2/5] END max_iter=100, penalty=l2, solver=sag;, score=0.687 total time=   0.0s\n",
      "[CV 3/5] END max_iter=100, penalty=l2, solver=sag;, score=0.739 total time=   0.0s\n",
      "[CV 4/5] END max_iter=100, penalty=l2, solver=sag;, score=0.692 total time=   0.0s\n",
      "[CV 5/5] END max_iter=100, penalty=l2, solver=sag;, score=0.699 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END max_iter=100, penalty=l2, solver=saga;, score=0.724 total time=   0.0s\n",
      "[CV 2/5] END max_iter=100, penalty=l2, solver=saga;, score=0.657 total time=   0.0s\n",
      "[CV 3/5] END max_iter=100, penalty=l2, solver=saga;, score=0.724 total time=   0.0s\n",
      "[CV 4/5] END max_iter=100, penalty=l2, solver=saga;, score=0.677 total time=   0.0s\n",
      "[CV 5/5] END max_iter=100, penalty=l2, solver=saga;, score=0.714 total time=   0.0s\n",
      "[CV 1/5] END max_iter=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_iter=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_iter=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_iter=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_iter=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END max_iter=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_iter=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_iter=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_iter=100, penalty=none, solver=newton-cg;, score=0.731 total time=   0.0s\n",
      "[CV 2/5] END max_iter=100, penalty=none, solver=newton-cg;, score=0.784 total time=   0.0s\n",
      "[CV 3/5] END max_iter=100, penalty=none, solver=newton-cg;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END max_iter=100, penalty=none, solver=newton-cg;, score=0.827 total time=   0.0s\n",
      "[CV 5/5] END max_iter=100, penalty=none, solver=newton-cg;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END max_iter=100, penalty=none, solver=lbfgs;, score=0.731 total time=   0.0s\n",
      "[CV 2/5] END max_iter=100, penalty=none, solver=lbfgs;, score=0.784 total time=   0.0s\n",
      "[CV 3/5] END max_iter=100, penalty=none, solver=lbfgs;, score=0.858 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END max_iter=100, penalty=none, solver=lbfgs;, score=0.827 total time=   0.0s\n",
      "[CV 5/5] END max_iter=100, penalty=none, solver=lbfgs;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END max_iter=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_iter=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_iter=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_iter=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_iter=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_iter=100, penalty=none, solver=sag;, score=0.724 total time=   0.0s\n",
      "[CV 2/5] END max_iter=100, penalty=none, solver=sag;, score=0.687 total time=   0.0s\n",
      "[CV 3/5] END max_iter=100, penalty=none, solver=sag;, score=0.739 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END max_iter=100, penalty=none, solver=sag;, score=0.692 total time=   0.0s\n",
      "[CV 5/5] END max_iter=100, penalty=none, solver=sag;, score=0.699 total time=   0.0s\n",
      "[CV 1/5] END max_iter=100, penalty=none, solver=saga;, score=0.716 total time=   0.0s\n",
      "[CV 2/5] END max_iter=100, penalty=none, solver=saga;, score=0.657 total time=   0.0s\n",
      "[CV 3/5] END max_iter=100, penalty=none, solver=saga;, score=0.724 total time=   0.0s\n",
      "[CV 4/5] END max_iter=100, penalty=none, solver=saga;, score=0.677 total time=   0.0s\n",
      "[CV 5/5] END max_iter=100, penalty=none, solver=saga;, score=0.714 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_iter=500, penalty=l1, solver=liblinear;, score=0.724 total time=   0.0s\n",
      "[CV 2/5] END max_iter=500, penalty=l1, solver=liblinear;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END max_iter=500, penalty=l1, solver=liblinear;, score=0.888 total time=   0.0s\n",
      "[CV 4/5] END max_iter=500, penalty=l1, solver=liblinear;, score=0.827 total time=   0.0s\n",
      "[CV 5/5] END max_iter=500, penalty=l1, solver=liblinear;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END max_iter=500, penalty=l1, solver=saga;, score=0.716 total time=   0.1s\n",
      "[CV 2/5] END max_iter=500, penalty=l1, solver=saga;, score=0.672 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END max_iter=500, penalty=l1, solver=saga;, score=0.739 total time=   0.0s\n",
      "[CV 4/5] END max_iter=500, penalty=l1, solver=saga;, score=0.692 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END max_iter=500, penalty=l1, solver=saga;, score=0.722 total time=   0.0s\n",
      "[CV 1/5] END max_iter=500, penalty=l2, solver=newton-cg;, score=0.731 total time=   0.0s\n",
      "[CV 2/5] END max_iter=500, penalty=l2, solver=newton-cg;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END max_iter=500, penalty=l2, solver=newton-cg;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END max_iter=500, penalty=l2, solver=newton-cg;, score=0.827 total time=   0.0s\n",
      "[CV 5/5] END max_iter=500, penalty=l2, solver=newton-cg;, score=0.782 total time=   0.0s\n",
      "[CV 1/5] END max_iter=500, penalty=l2, solver=lbfgs;, score=0.731 total time=   0.0s\n",
      "[CV 2/5] END max_iter=500, penalty=l2, solver=lbfgs;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END max_iter=500, penalty=l2, solver=lbfgs;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END max_iter=500, penalty=l2, solver=lbfgs;, score=0.827 total time=   0.0s\n",
      "[CV 5/5] END max_iter=500, penalty=l2, solver=lbfgs;, score=0.782 total time=   0.0s\n",
      "[CV 1/5] END max_iter=500, penalty=l2, solver=liblinear;, score=0.724 total time=   0.0s\n",
      "[CV 2/5] END max_iter=500, penalty=l2, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 3/5] END max_iter=500, penalty=l2, solver=liblinear;, score=0.896 total time=   0.0s\n",
      "[CV 4/5] END max_iter=500, penalty=l2, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 5/5] END max_iter=500, penalty=l2, solver=liblinear;, score=0.789 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END max_iter=500, penalty=l2, solver=sag;, score=0.731 total time=   0.0s\n",
      "[CV 2/5] END max_iter=500, penalty=l2, solver=sag;, score=0.709 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END max_iter=500, penalty=l2, solver=sag;, score=0.739 total time=   0.0s\n",
      "[CV 4/5] END max_iter=500, penalty=l2, solver=sag;, score=0.692 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END max_iter=500, penalty=l2, solver=sag;, score=0.737 total time=   0.0s\n",
      "[CV 1/5] END max_iter=500, penalty=l2, solver=saga;, score=0.716 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END max_iter=500, penalty=l2, solver=saga;, score=0.672 total time=   0.0s\n",
      "[CV 3/5] END max_iter=500, penalty=l2, solver=saga;, score=0.739 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END max_iter=500, penalty=l2, solver=saga;, score=0.692 total time=   0.0s\n",
      "[CV 5/5] END max_iter=500, penalty=l2, solver=saga;, score=0.722 total time=   0.0s\n",
      "[CV 1/5] END max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_iter=500, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_iter=500, penalty=none, solver=newton-cg;, score=0.731 total time=   0.0s\n",
      "[CV 2/5] END max_iter=500, penalty=none, solver=newton-cg;, score=0.784 total time=   0.0s\n",
      "[CV 3/5] END max_iter=500, penalty=none, solver=newton-cg;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END max_iter=500, penalty=none, solver=newton-cg;, score=0.827 total time=   0.0s\n",
      "[CV 5/5] END max_iter=500, penalty=none, solver=newton-cg;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END max_iter=500, penalty=none, solver=lbfgs;, score=0.731 total time=   0.0s\n",
      "[CV 2/5] END max_iter=500, penalty=none, solver=lbfgs;, score=0.784 total time=   0.0s\n",
      "[CV 3/5] END max_iter=500, penalty=none, solver=lbfgs;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END max_iter=500, penalty=none, solver=lbfgs;, score=0.827 total time=   0.0s\n",
      "[CV 5/5] END max_iter=500, penalty=none, solver=lbfgs;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END max_iter=500, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_iter=500, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_iter=500, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_iter=500, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_iter=500, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END max_iter=500, penalty=none, solver=sag;, score=0.731 total time=   0.0s\n",
      "[CV 2/5] END max_iter=500, penalty=none, solver=sag;, score=0.709 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END max_iter=500, penalty=none, solver=sag;, score=0.739 total time=   0.0s\n",
      "[CV 4/5] END max_iter=500, penalty=none, solver=sag;, score=0.692 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END max_iter=500, penalty=none, solver=sag;, score=0.737 total time=   0.0s\n",
      "[CV 1/5] END max_iter=500, penalty=none, solver=saga;, score=0.716 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END max_iter=500, penalty=none, solver=saga;, score=0.672 total time=   0.0s\n",
      "[CV 3/5] END max_iter=500, penalty=none, solver=saga;, score=0.739 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END max_iter=500, penalty=none, solver=saga;, score=0.692 total time=   0.0s\n",
      "[CV 5/5] END max_iter=500, penalty=none, solver=saga;, score=0.722 total time=   0.0s\n",
      "[CV 1/5] END max_iter=1000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_iter=1000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_iter=1000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_iter=1000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_iter=1000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_iter=1000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_iter=1000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_iter=1000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_iter=1000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_iter=1000, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_iter=1000, penalty=l1, solver=liblinear;, score=0.724 total time=   0.0s\n",
      "[CV 2/5] END max_iter=1000, penalty=l1, solver=liblinear;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END max_iter=1000, penalty=l1, solver=liblinear;, score=0.888 total time=   0.0s\n",
      "[CV 4/5] END max_iter=1000, penalty=l1, solver=liblinear;, score=0.827 total time=   0.0s\n",
      "[CV 5/5] END max_iter=1000, penalty=l1, solver=liblinear;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END max_iter=1000, penalty=l1, solver=saga;, score=0.731 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END max_iter=1000, penalty=l1, solver=saga;, score=0.716 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END max_iter=1000, penalty=l1, solver=saga;, score=0.739 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END max_iter=1000, penalty=l1, solver=saga;, score=0.692 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END max_iter=1000, penalty=l1, solver=saga;, score=0.737 total time=   0.2s\n",
      "[CV 1/5] END max_iter=1000, penalty=l2, solver=newton-cg;, score=0.731 total time=   0.0s\n",
      "[CV 2/5] END max_iter=1000, penalty=l2, solver=newton-cg;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END max_iter=1000, penalty=l2, solver=newton-cg;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END max_iter=1000, penalty=l2, solver=newton-cg;, score=0.827 total time=   0.0s\n",
      "[CV 5/5] END max_iter=1000, penalty=l2, solver=newton-cg;, score=0.782 total time=   0.0s\n",
      "[CV 1/5] END max_iter=1000, penalty=l2, solver=lbfgs;, score=0.731 total time=   0.0s\n",
      "[CV 2/5] END max_iter=1000, penalty=l2, solver=lbfgs;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END max_iter=1000, penalty=l2, solver=lbfgs;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END max_iter=1000, penalty=l2, solver=lbfgs;, score=0.827 total time=   0.0s\n",
      "[CV 5/5] END max_iter=1000, penalty=l2, solver=lbfgs;, score=0.782 total time=   0.0s\n",
      "[CV 1/5] END max_iter=1000, penalty=l2, solver=liblinear;, score=0.724 total time=   0.0s\n",
      "[CV 2/5] END max_iter=1000, penalty=l2, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 3/5] END max_iter=1000, penalty=l2, solver=liblinear;, score=0.896 total time=   0.0s\n",
      "[CV 4/5] END max_iter=1000, penalty=l2, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 5/5] END max_iter=1000, penalty=l2, solver=liblinear;, score=0.789 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END max_iter=1000, penalty=l2, solver=sag;, score=0.724 total time=   0.1s\n",
      "[CV 2/5] END max_iter=1000, penalty=l2, solver=sag;, score=0.761 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END max_iter=1000, penalty=l2, solver=sag;, score=0.769 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END max_iter=1000, penalty=l2, solver=sag;, score=0.714 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END max_iter=1000, penalty=l2, solver=sag;, score=0.752 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END max_iter=1000, penalty=l2, solver=saga;, score=0.731 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END max_iter=1000, penalty=l2, solver=saga;, score=0.709 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END max_iter=1000, penalty=l2, solver=saga;, score=0.739 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END max_iter=1000, penalty=l2, solver=saga;, score=0.692 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END max_iter=1000, penalty=l2, solver=saga;, score=0.737 total time=   0.2s\n",
      "[CV 1/5] END max_iter=1000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_iter=1000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_iter=1000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_iter=1000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_iter=1000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_iter=1000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_iter=1000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_iter=1000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_iter=1000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_iter=1000, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_iter=1000, penalty=none, solver=newton-cg;, score=0.731 total time=   0.0s\n",
      "[CV 2/5] END max_iter=1000, penalty=none, solver=newton-cg;, score=0.784 total time=   0.0s\n",
      "[CV 3/5] END max_iter=1000, penalty=none, solver=newton-cg;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END max_iter=1000, penalty=none, solver=newton-cg;, score=0.827 total time=   0.0s\n",
      "[CV 5/5] END max_iter=1000, penalty=none, solver=newton-cg;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END max_iter=1000, penalty=none, solver=lbfgs;, score=0.731 total time=   0.0s\n",
      "[CV 2/5] END max_iter=1000, penalty=none, solver=lbfgs;, score=0.784 total time=   0.0s\n",
      "[CV 3/5] END max_iter=1000, penalty=none, solver=lbfgs;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END max_iter=1000, penalty=none, solver=lbfgs;, score=0.827 total time=   0.0s\n",
      "[CV 5/5] END max_iter=1000, penalty=none, solver=lbfgs;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END max_iter=1000, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_iter=1000, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_iter=1000, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_iter=1000, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_iter=1000, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END max_iter=1000, penalty=none, solver=sag;, score=0.724 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END max_iter=1000, penalty=none, solver=sag;, score=0.776 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END max_iter=1000, penalty=none, solver=sag;, score=0.769 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END max_iter=1000, penalty=none, solver=sag;, score=0.714 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END max_iter=1000, penalty=none, solver=sag;, score=0.752 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END max_iter=1000, penalty=none, solver=saga;, score=0.731 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END max_iter=1000, penalty=none, solver=saga;, score=0.709 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END max_iter=1000, penalty=none, solver=saga;, score=0.739 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END max_iter=1000, penalty=none, solver=saga;, score=0.692 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "135 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1101, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 78, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.80089777        nan 0.69759847 0.79941645\n",
      " 0.79941645 0.80240153 0.70804623 0.69909101        nan        nan\n",
      "        nan        nan        nan 0.79492762 0.79492762        nan\n",
      " 0.70804623 0.69759847        nan        nan 0.8023903         nan\n",
      " 0.7080799  0.79941645 0.79941645 0.80240153 0.72153518 0.7080799\n",
      "        nan        nan        nan        nan        nan 0.79492762\n",
      " 0.79492762        nan 0.72153518 0.7080799         nan        nan\n",
      " 0.8023903         nan 0.72302772 0.79941645 0.79941645 0.80240153\n",
      " 0.74397935 0.72153518        nan        nan        nan        nan\n",
      "        nan 0.79492762 0.79492762        nan 0.74696443 0.72153518]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END max_iter=1000, penalty=none, solver=saga;, score=0.737 total time=   0.2s\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END criterion=gini, min_samples_split=2;, score=0.754 total time=   0.3s\n",
      "[CV 2/5] END criterion=gini, min_samples_split=2;, score=0.806 total time=   0.3s\n",
      "[CV 3/5] END criterion=gini, min_samples_split=2;, score=0.821 total time=   0.3s\n",
      "[CV 4/5] END criterion=gini, min_samples_split=2;, score=0.812 total time=   0.3s\n",
      "[CV 5/5] END criterion=gini, min_samples_split=2;, score=0.842 total time=   0.3s\n",
      "[CV 1/5] END criterion=gini, min_samples_split=4;, score=0.799 total time=   0.3s\n",
      "[CV 2/5] END criterion=gini, min_samples_split=4;, score=0.821 total time=   0.3s\n",
      "[CV 3/5] END criterion=gini, min_samples_split=4;, score=0.858 total time=   0.3s\n",
      "[CV 4/5] END criterion=gini, min_samples_split=4;, score=0.850 total time=   0.3s\n",
      "[CV 5/5] END criterion=gini, min_samples_split=4;, score=0.865 total time=   0.3s\n",
      "[CV 1/5] END criterion=gini, min_samples_split=8;, score=0.791 total time=   0.3s\n",
      "[CV 2/5] END criterion=gini, min_samples_split=8;, score=0.821 total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, min_samples_split=8;, score=0.858 total time=   0.3s\n",
      "[CV 4/5] END criterion=gini, min_samples_split=8;, score=0.857 total time=   0.3s\n",
      "[CV 5/5] END criterion=gini, min_samples_split=8;, score=0.835 total time=   0.3s\n",
      "[CV 1/5] END criterion=entropy, min_samples_split=2;, score=0.776 total time=   0.4s\n",
      "[CV 2/5] END criterion=entropy, min_samples_split=2;, score=0.828 total time=   0.4s\n",
      "[CV 3/5] END criterion=entropy, min_samples_split=2;, score=0.836 total time=   0.4s\n",
      "[CV 4/5] END criterion=entropy, min_samples_split=2;, score=0.835 total time=   0.4s\n",
      "[CV 5/5] END criterion=entropy, min_samples_split=2;, score=0.850 total time=   0.4s\n",
      "[CV 1/5] END criterion=entropy, min_samples_split=4;, score=0.784 total time=   0.4s\n",
      "[CV 2/5] END criterion=entropy, min_samples_split=4;, score=0.813 total time=   0.4s\n",
      "[CV 3/5] END criterion=entropy, min_samples_split=4;, score=0.858 total time=   0.4s\n",
      "[CV 4/5] END criterion=entropy, min_samples_split=4;, score=0.865 total time=   0.3s\n",
      "[CV 5/5] END criterion=entropy, min_samples_split=4;, score=0.827 total time=   0.4s\n",
      "[CV 1/5] END criterion=entropy, min_samples_split=8;, score=0.784 total time=   0.3s\n",
      "[CV 2/5] END criterion=entropy, min_samples_split=8;, score=0.806 total time=   0.4s\n",
      "[CV 3/5] END criterion=entropy, min_samples_split=8;, score=0.866 total time=   0.3s\n",
      "[CV 4/5] END criterion=entropy, min_samples_split=8;, score=0.857 total time=   0.3s\n",
      "[CV 5/5] END criterion=entropy, min_samples_split=8;, score=0.850 total time=   0.3s\n",
      "[CV 1/5] END criterion=log_loss, min_samples_split=2;, score=0.754 total time=   0.4s\n",
      "[CV 2/5] END criterion=log_loss, min_samples_split=2;, score=0.813 total time=   0.4s\n",
      "[CV 3/5] END criterion=log_loss, min_samples_split=2;, score=0.836 total time=   0.3s\n",
      "[CV 4/5] END criterion=log_loss, min_samples_split=2;, score=0.827 total time=   0.3s\n",
      "[CV 5/5] END criterion=log_loss, min_samples_split=2;, score=0.842 total time=   0.3s\n",
      "[CV 1/5] END criterion=log_loss, min_samples_split=4;, score=0.776 total time=   0.3s\n",
      "[CV 2/5] END criterion=log_loss, min_samples_split=4;, score=0.828 total time=   0.4s\n",
      "[CV 3/5] END criterion=log_loss, min_samples_split=4;, score=0.843 total time=   0.3s\n",
      "[CV 4/5] END criterion=log_loss, min_samples_split=4;, score=0.850 total time=   0.4s\n",
      "[CV 5/5] END criterion=log_loss, min_samples_split=4;, score=0.835 total time=   0.4s\n",
      "[CV 1/5] END criterion=log_loss, min_samples_split=8;, score=0.806 total time=   0.3s\n",
      "[CV 2/5] END criterion=log_loss, min_samples_split=8;, score=0.806 total time=   0.3s\n",
      "[CV 3/5] END criterion=log_loss, min_samples_split=8;, score=0.858 total time=   0.3s\n",
      "[CV 4/5] END criterion=log_loss, min_samples_split=8;, score=0.857 total time=   0.3s\n",
      "[CV 5/5] END criterion=log_loss, min_samples_split=8;, score=0.835 total time=   0.3s\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.634 total time=   0.0s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.627 total time=   0.0s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.627 total time=   0.0s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.632 total time=   0.0s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.632 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.634 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.627 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.627 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.632 total time=   0.0s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.632 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.664 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.634 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.642 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.632 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.677 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.687 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.634 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.716 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.654 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.677 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.716 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.627 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.701 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.699 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.684 total time=   0.0s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.634 total time=   0.0s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.657 total time=   0.0s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.664 total time=   0.0s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.677 total time=   0.0s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.684 total time=   0.0s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.679 total time=   0.0s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.672 total time=   0.0s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.687 total time=   0.0s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.624 total time=   0.0s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.744 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.739 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.657 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.716 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.654 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.709 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.649 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.687 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.654 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.729 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.709 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.634 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.716 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.684 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.684 total time=   0.0s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.642 total time=   0.0s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.649 total time=   0.0s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.687 total time=   0.0s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.677 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.669 total time=   0.0s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.687 total time=   0.0s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.672 total time=   0.0s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.716 total time=   0.0s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.692 total time=   0.0s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.767 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.709 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.679 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.739 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.692 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.746 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.679 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.709 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.692 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.759 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.709 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.634 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.701 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.677 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.634 total time=   0.0s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.627 total time=   0.0s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.679 total time=   0.0s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.692 total time=   0.0s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.647 total time=   0.0s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.687 total time=   0.0s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.694 total time=   0.0s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.709 total time=   0.0s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.684 total time=   0.0s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.782 total time=   0.0s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.701 total time=   0.0s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.776 total time=   0.0s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.789 total time=   0.0s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.782 total time=   0.0s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.701 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.791 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.836 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.774 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.827 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.746 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.716 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.769 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.729 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.619 total time=   0.0s\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.649 total time=   0.0s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.679 total time=   0.0s\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.692 total time=   0.0s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.654 total time=   0.0s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.687 total time=   0.2s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.701 total time=   0.1s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.716 total time=   0.0s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.692 total time=   0.0s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.767 total time=   0.1s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.687 total time=   0.6s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.746 total time=   0.3s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.769 total time=   0.1s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.774 total time=   0.2s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.782 total time=   0.3s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.739 total time=   0.1s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.784 total time=   0.2s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.821 total time=   0.1s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.797 total time=   0.1s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.767 total time=   0.2s\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.701 total time=   0.0s\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.813 total time=   0.0s\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.866 total time=   0.0s\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.835 total time=   0.0s\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.812 total time=   0.0s\n",
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "[CV 1/5] END loss=hinge, max_iter=5, penalty=l2;, score=0.634 total time=   0.0s\n",
      "[CV 2/5] END loss=hinge, max_iter=5, penalty=l2;, score=0.604 total time=   0.0s\n",
      "[CV 3/5] END loss=hinge, max_iter=5, penalty=l2;, score=0.627 total time=   0.0s\n",
      "[CV 4/5] END loss=hinge, max_iter=5, penalty=l2;, score=0.617 total time=   0.0s\n",
      "[CV 5/5] END loss=hinge, max_iter=5, penalty=l2;, score=0.632 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END loss=hinge, max_iter=5, penalty=l1;, score=0.679 total time=   0.0s\n",
      "[CV 2/5] END loss=hinge, max_iter=5, penalty=l1;, score=0.627 total time=   0.0s\n",
      "[CV 3/5] END loss=hinge, max_iter=5, penalty=l1;, score=0.754 total time=   0.0s\n",
      "[CV 4/5] END loss=hinge, max_iter=5, penalty=l1;, score=0.707 total time=   0.0s\n",
      "[CV 5/5] END loss=hinge, max_iter=5, penalty=l1;, score=0.684 total time=   0.0s\n",
      "[CV 1/5] END loss=hinge, max_iter=5, penalty=elasticnet;, score=0.679 total time=   0.0s\n",
      "[CV 2/5] END loss=hinge, max_iter=5, penalty=elasticnet;, score=0.627 total time=   0.0s\n",
      "[CV 3/5] END loss=hinge, max_iter=5, penalty=elasticnet;, score=0.627 total time=   0.0s\n",
      "[CV 4/5] END loss=hinge, max_iter=5, penalty=elasticnet;, score=0.707 total time=   0.0s\n",
      "[CV 5/5] END loss=hinge, max_iter=5, penalty=elasticnet;, score=0.632 total time=   0.0s\n",
      "[CV 1/5] END loss=hinge, max_iter=50, penalty=l2;, score=0.701 total time=   0.0s\n",
      "[CV 2/5] END loss=hinge, max_iter=50, penalty=l2;, score=0.709 total time=   0.0s\n",
      "[CV 3/5] END loss=hinge, max_iter=50, penalty=l2;, score=0.627 total time=   0.0s\n",
      "[CV 4/5] END loss=hinge, max_iter=50, penalty=l2;, score=0.692 total time=   0.0s\n",
      "[CV 5/5] END loss=hinge, max_iter=50, penalty=l2;, score=0.436 total time=   0.0s\n",
      "[CV 1/5] END loss=hinge, max_iter=50, penalty=l1;, score=0.701 total time=   0.0s\n",
      "[CV 2/5] END loss=hinge, max_iter=50, penalty=l1;, score=0.769 total time=   0.0s\n",
      "[CV 3/5] END loss=hinge, max_iter=50, penalty=l1;, score=0.754 total time=   0.0s\n",
      "[CV 4/5] END loss=hinge, max_iter=50, penalty=l1;, score=0.789 total time=   0.0s\n",
      "[CV 5/5] END loss=hinge, max_iter=50, penalty=l1;, score=0.639 total time=   0.0s\n",
      "[CV 1/5] END loss=hinge, max_iter=50, penalty=elasticnet;, score=0.769 total time=   0.0s\n",
      "[CV 2/5] END loss=hinge, max_iter=50, penalty=elasticnet;, score=0.575 total time=   0.0s\n",
      "[CV 3/5] END loss=hinge, max_iter=50, penalty=elasticnet;, score=0.776 total time=   0.0s\n",
      "[CV 4/5] END loss=hinge, max_iter=50, penalty=elasticnet;, score=0.662 total time=   0.0s\n",
      "[CV 5/5] END loss=hinge, max_iter=50, penalty=elasticnet;, score=0.737 total time=   0.0s\n",
      "[CV 1/5] END loss=hinge, max_iter=100, penalty=l2;, score=0.746 total time=   0.0s\n",
      "[CV 2/5] END loss=hinge, max_iter=100, penalty=l2;, score=0.381 total time=   0.0s\n",
      "[CV 3/5] END loss=hinge, max_iter=100, penalty=l2;, score=0.716 total time=   0.0s\n",
      "[CV 4/5] END loss=hinge, max_iter=100, penalty=l2;, score=0.677 total time=   0.0s\n",
      "[CV 5/5] END loss=hinge, max_iter=100, penalty=l2;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END loss=hinge, max_iter=100, penalty=l1;, score=0.709 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END loss=hinge, max_iter=100, penalty=l1;, score=0.724 total time=   0.0s\n",
      "[CV 3/5] END loss=hinge, max_iter=100, penalty=l1;, score=0.746 total time=   0.0s\n",
      "[CV 4/5] END loss=hinge, max_iter=100, penalty=l1;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END loss=hinge, max_iter=100, penalty=l1;, score=0.684 total time=   0.0s\n",
      "[CV 1/5] END loss=hinge, max_iter=100, penalty=elasticnet;, score=0.679 total time=   0.0s\n",
      "[CV 2/5] END loss=hinge, max_iter=100, penalty=elasticnet;, score=0.754 total time=   0.0s\n",
      "[CV 3/5] END loss=hinge, max_iter=100, penalty=elasticnet;, score=0.739 total time=   0.0s\n",
      "[CV 4/5] END loss=hinge, max_iter=100, penalty=elasticnet;, score=0.699 total time=   0.0s\n",
      "[CV 5/5] END loss=hinge, max_iter=100, penalty=elasticnet;, score=0.722 total time=   0.0s\n",
      "[CV 1/5] END loss=hinge, max_iter=500, penalty=l2;, score=0.716 total time=   0.0s\n",
      "[CV 2/5] END loss=hinge, max_iter=500, penalty=l2;, score=0.657 total time=   0.0s\n",
      "[CV 3/5] END loss=hinge, max_iter=500, penalty=l2;, score=0.739 total time=   0.0s\n",
      "[CV 4/5] END loss=hinge, max_iter=500, penalty=l2;, score=0.617 total time=   0.0s\n",
      "[CV 5/5] END loss=hinge, max_iter=500, penalty=l2;, score=0.759 total time=   0.0s\n",
      "[CV 1/5] END loss=hinge, max_iter=500, penalty=l1;, score=0.634 total time=   0.0s\n",
      "[CV 2/5] END loss=hinge, max_iter=500, penalty=l1;, score=0.784 total time=   0.0s\n",
      "[CV 3/5] END loss=hinge, max_iter=500, penalty=l1;, score=0.836 total time=   0.0s\n",
      "[CV 4/5] END loss=hinge, max_iter=500, penalty=l1;, score=0.707 total time=   0.0s\n",
      "[CV 5/5] END loss=hinge, max_iter=500, penalty=l1;, score=0.391 total time=   0.0s\n",
      "[CV 1/5] END loss=hinge, max_iter=500, penalty=elasticnet;, score=0.694 total time=   0.0s\n",
      "[CV 2/5] END loss=hinge, max_iter=500, penalty=elasticnet;, score=0.664 total time=   0.0s\n",
      "[CV 3/5] END loss=hinge, max_iter=500, penalty=elasticnet;, score=0.836 total time=   0.0s\n",
      "[CV 4/5] END loss=hinge, max_iter=500, penalty=elasticnet;, score=0.707 total time=   0.0s\n",
      "[CV 5/5] END loss=hinge, max_iter=500, penalty=elasticnet;, score=0.767 total time=   0.0s\n",
      "[CV 1/5] END loss=hinge, max_iter=1000, penalty=l2;, score=0.410 total time=   0.0s\n",
      "[CV 2/5] END loss=hinge, max_iter=1000, penalty=l2;, score=0.754 total time=   0.0s\n",
      "[CV 3/5] END loss=hinge, max_iter=1000, penalty=l2;, score=0.731 total time=   0.0s\n",
      "[CV 4/5] END loss=hinge, max_iter=1000, penalty=l2;, score=0.617 total time=   0.0s\n",
      "[CV 5/5] END loss=hinge, max_iter=1000, penalty=l2;, score=0.752 total time=   0.0s\n",
      "[CV 1/5] END loss=hinge, max_iter=1000, penalty=l1;, score=0.403 total time=   0.0s\n",
      "[CV 2/5] END loss=hinge, max_iter=1000, penalty=l1;, score=0.642 total time=   0.0s\n",
      "[CV 3/5] END loss=hinge, max_iter=1000, penalty=l1;, score=0.463 total time=   0.0s\n",
      "[CV 4/5] END loss=hinge, max_iter=1000, penalty=l1;, score=0.789 total time=   0.0s\n",
      "[CV 5/5] END loss=hinge, max_iter=1000, penalty=l1;, score=0.759 total time=   0.0s\n",
      "[CV 1/5] END loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.627 total time=   0.0s\n",
      "[CV 2/5] END loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.746 total time=   0.0s\n",
      "[CV 3/5] END loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.627 total time=   0.0s\n",
      "[CV 4/5] END loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.639 total time=   0.0s\n",
      "[CV 5/5] END loss=hinge, max_iter=1000, penalty=elasticnet;, score=0.767 total time=   0.0s\n",
      "[CV 1/5] END loss=log_loss, max_iter=5, penalty=l2;, score=0.746 total time=   0.0s\n",
      "[CV 2/5] END loss=log_loss, max_iter=5, penalty=l2;, score=0.627 total time=   0.0s\n",
      "[CV 3/5] END loss=log_loss, max_iter=5, penalty=l2;, score=0.478 total time=   0.0s\n",
      "[CV 4/5] END loss=log_loss, max_iter=5, penalty=l2;, score=0.632 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END loss=log_loss, max_iter=5, penalty=l2;, score=0.632 total time=   0.0s\n",
      "[CV 1/5] END loss=log_loss, max_iter=5, penalty=l1;, score=0.664 total time=   0.0s\n",
      "[CV 2/5] END loss=log_loss, max_iter=5, penalty=l1;, score=0.694 total time=   0.0s\n",
      "[CV 3/5] END loss=log_loss, max_iter=5, penalty=l1;, score=0.627 total time=   0.0s\n",
      "[CV 4/5] END loss=log_loss, max_iter=5, penalty=l1;, score=0.414 total time=   0.0s\n",
      "[CV 5/5] END loss=log_loss, max_iter=5, penalty=l1;, score=0.398 total time=   0.0s\n",
      "[CV 1/5] END loss=log_loss, max_iter=5, penalty=elasticnet;, score=0.634 total time=   0.0s\n",
      "[CV 2/5] END loss=log_loss, max_iter=5, penalty=elasticnet;, score=0.627 total time=   0.0s\n",
      "[CV 3/5] END loss=log_loss, max_iter=5, penalty=elasticnet;, score=0.627 total time=   0.0s\n",
      "[CV 4/5] END loss=log_loss, max_iter=5, penalty=elasticnet;, score=0.684 total time=   0.0s\n",
      "[CV 5/5] END loss=log_loss, max_iter=5, penalty=elasticnet;, score=0.759 total time=   0.0s\n",
      "[CV 1/5] END loss=log_loss, max_iter=50, penalty=l2;, score=0.455 total time=   0.0s\n",
      "[CV 2/5] END loss=log_loss, max_iter=50, penalty=l2;, score=0.716 total time=   0.0s\n",
      "[CV 3/5] END loss=log_loss, max_iter=50, penalty=l2;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END loss=log_loss, max_iter=50, penalty=l2;, score=0.729 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END loss=log_loss, max_iter=50, penalty=l2;, score=0.647 total time=   0.0s\n",
      "[CV 1/5] END loss=log_loss, max_iter=50, penalty=l1;, score=0.739 total time=   0.0s\n",
      "[CV 2/5] END loss=log_loss, max_iter=50, penalty=l1;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END loss=log_loss, max_iter=50, penalty=l1;, score=0.739 total time=   0.0s\n",
      "[CV 4/5] END loss=log_loss, max_iter=50, penalty=l1;, score=0.729 total time=   0.0s\n",
      "[CV 5/5] END loss=log_loss, max_iter=50, penalty=l1;, score=0.699 total time=   0.0s\n",
      "[CV 1/5] END loss=log_loss, max_iter=50, penalty=elasticnet;, score=0.724 total time=   0.0s\n",
      "[CV 2/5] END loss=log_loss, max_iter=50, penalty=elasticnet;, score=0.373 total time=   0.0s\n",
      "[CV 3/5] END loss=log_loss, max_iter=50, penalty=elasticnet;, score=0.843 total time=   0.0s\n",
      "[CV 4/5] END loss=log_loss, max_iter=50, penalty=elasticnet;, score=0.692 total time=   0.0s\n",
      "[CV 5/5] END loss=log_loss, max_iter=50, penalty=elasticnet;, score=0.789 total time=   0.0s\n",
      "[CV 1/5] END loss=log_loss, max_iter=100, penalty=l2;, score=0.701 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END loss=log_loss, max_iter=100, penalty=l2;, score=0.649 total time=   0.0s\n",
      "[CV 3/5] END loss=log_loss, max_iter=100, penalty=l2;, score=0.739 total time=   0.0s\n",
      "[CV 4/5] END loss=log_loss, max_iter=100, penalty=l2;, score=0.662 total time=   0.0s\n",
      "[CV 5/5] END loss=log_loss, max_iter=100, penalty=l2;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END loss=log_loss, max_iter=100, penalty=l1;, score=0.448 total time=   0.0s\n",
      "[CV 2/5] END loss=log_loss, max_iter=100, penalty=l1;, score=0.403 total time=   0.0s\n",
      "[CV 3/5] END loss=log_loss, max_iter=100, penalty=l1;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END loss=log_loss, max_iter=100, penalty=l1;, score=0.639 total time=   0.0s\n",
      "[CV 5/5] END loss=log_loss, max_iter=100, penalty=l1;, score=0.737 total time=   0.0s\n",
      "[CV 1/5] END loss=log_loss, max_iter=100, penalty=elasticnet;, score=0.634 total time=   0.0s\n",
      "[CV 2/5] END loss=log_loss, max_iter=100, penalty=elasticnet;, score=0.716 total time=   0.0s\n",
      "[CV 3/5] END loss=log_loss, max_iter=100, penalty=elasticnet;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END loss=log_loss, max_iter=100, penalty=elasticnet;, score=0.639 total time=   0.0s\n",
      "[CV 5/5] END loss=log_loss, max_iter=100, penalty=elasticnet;, score=0.767 total time=   0.0s\n",
      "[CV 1/5] END loss=log_loss, max_iter=500, penalty=l2;, score=0.687 total time=   0.0s\n",
      "[CV 2/5] END loss=log_loss, max_iter=500, penalty=l2;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END loss=log_loss, max_iter=500, penalty=l2;, score=0.679 total time=   0.0s\n",
      "[CV 4/5] END loss=log_loss, max_iter=500, penalty=l2;, score=0.684 total time=   0.0s\n",
      "[CV 5/5] END loss=log_loss, max_iter=500, penalty=l2;, score=0.556 total time=   0.0s\n",
      "[CV 1/5] END loss=log_loss, max_iter=500, penalty=l1;, score=0.724 total time=   0.0s\n",
      "[CV 2/5] END loss=log_loss, max_iter=500, penalty=l1;, score=0.731 total time=   0.0s\n",
      "[CV 3/5] END loss=log_loss, max_iter=500, penalty=l1;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END loss=log_loss, max_iter=500, penalty=l1;, score=0.714 total time=   0.0s\n",
      "[CV 5/5] END loss=log_loss, max_iter=500, penalty=l1;, score=0.789 total time=   0.0s\n",
      "[CV 1/5] END loss=log_loss, max_iter=500, penalty=elasticnet;, score=0.687 total time=   0.0s\n",
      "[CV 2/5] END loss=log_loss, max_iter=500, penalty=elasticnet;, score=0.746 total time=   0.0s\n",
      "[CV 3/5] END loss=log_loss, max_iter=500, penalty=elasticnet;, score=0.761 total time=   0.0s\n",
      "[CV 4/5] END loss=log_loss, max_iter=500, penalty=elasticnet;, score=0.421 total time=   0.0s\n",
      "[CV 5/5] END loss=log_loss, max_iter=500, penalty=elasticnet;, score=0.368 total time=   0.0s\n",
      "[CV 1/5] END loss=log_loss, max_iter=1000, penalty=l2;, score=0.664 total time=   0.0s\n",
      "[CV 2/5] END loss=log_loss, max_iter=1000, penalty=l2;, score=0.746 total time=   0.0s\n",
      "[CV 3/5] END loss=log_loss, max_iter=1000, penalty=l2;, score=0.866 total time=   0.0s\n",
      "[CV 4/5] END loss=log_loss, max_iter=1000, penalty=l2;, score=0.684 total time=   0.0s\n",
      "[CV 5/5] END loss=log_loss, max_iter=1000, penalty=l2;, score=0.752 total time=   0.0s\n",
      "[CV 1/5] END loss=log_loss, max_iter=1000, penalty=l1;, score=0.604 total time=   0.0s\n",
      "[CV 2/5] END loss=log_loss, max_iter=1000, penalty=l1;, score=0.754 total time=   0.0s\n",
      "[CV 3/5] END loss=log_loss, max_iter=1000, penalty=l1;, score=0.866 total time=   0.0s\n",
      "[CV 4/5] END loss=log_loss, max_iter=1000, penalty=l1;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END loss=log_loss, max_iter=1000, penalty=l1;, score=0.767 total time=   0.0s\n",
      "[CV 1/5] END loss=log_loss, max_iter=1000, penalty=elasticnet;, score=0.657 total time=   0.0s\n",
      "[CV 2/5] END loss=log_loss, max_iter=1000, penalty=elasticnet;, score=0.709 total time=   0.0s\n",
      "[CV 3/5] END loss=log_loss, max_iter=1000, penalty=elasticnet;, score=0.657 total time=   0.0s\n",
      "[CV 4/5] END loss=log_loss, max_iter=1000, penalty=elasticnet;, score=0.647 total time=   0.0s\n",
      "[CV 5/5] END loss=log_loss, max_iter=1000, penalty=elasticnet;, score=0.624 total time=   0.0s\n",
      "[CV 1/5] END ...loss=loss, max_iter=5, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...loss=loss, max_iter=5, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...loss=loss, max_iter=5, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...loss=loss, max_iter=5, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...loss=loss, max_iter=5, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...loss=loss, max_iter=5, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...loss=loss, max_iter=5, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...loss=loss, max_iter=5, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...loss=loss, max_iter=5, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...loss=loss, max_iter=5, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END loss=loss, max_iter=5, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END loss=loss, max_iter=5, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END loss=loss, max_iter=5, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END loss=loss, max_iter=5, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END loss=loss, max_iter=5, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..loss=loss, max_iter=50, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..loss=loss, max_iter=50, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..loss=loss, max_iter=50, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..loss=loss, max_iter=50, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..loss=loss, max_iter=50, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..loss=loss, max_iter=50, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..loss=loss, max_iter=50, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..loss=loss, max_iter=50, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..loss=loss, max_iter=50, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..loss=loss, max_iter=50, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END loss=loss, max_iter=50, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END loss=loss, max_iter=50, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END loss=loss, max_iter=50, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END loss=loss, max_iter=50, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END loss=loss, max_iter=50, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .loss=loss, max_iter=100, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .loss=loss, max_iter=100, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .loss=loss, max_iter=100, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .loss=loss, max_iter=100, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .loss=loss, max_iter=100, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .loss=loss, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .loss=loss, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .loss=loss, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .loss=loss, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .loss=loss, max_iter=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END loss=loss, max_iter=100, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END loss=loss, max_iter=100, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END loss=loss, max_iter=100, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END loss=loss, max_iter=100, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END loss=loss, max_iter=100, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .loss=loss, max_iter=500, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .loss=loss, max_iter=500, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .loss=loss, max_iter=500, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .loss=loss, max_iter=500, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .loss=loss, max_iter=500, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .loss=loss, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .loss=loss, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .loss=loss, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .loss=loss, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .loss=loss, max_iter=500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END loss=loss, max_iter=500, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END loss=loss, max_iter=500, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END loss=loss, max_iter=500, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END loss=loss, max_iter=500, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END loss=loss, max_iter=500, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END loss=loss, max_iter=1000, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END loss=loss, max_iter=1000, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END loss=loss, max_iter=1000, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END loss=loss, max_iter=1000, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END loss=loss, max_iter=1000, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END loss=loss, max_iter=1000, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END loss=loss, max_iter=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END loss=loss, max_iter=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END loss=loss, max_iter=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END loss=loss, max_iter=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END loss=loss, max_iter=1000, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END loss=loss, max_iter=1000, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END loss=loss, max_iter=1000, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END loss=loss, max_iter=1000, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END loss=loss, max_iter=1000, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END loss=modified_huber, max_iter=5, penalty=l2;, score=0.739 total time=   0.0s\n",
      "[CV 2/5] END loss=modified_huber, max_iter=5, penalty=l2;, score=0.381 total time=   0.0s\n",
      "[CV 3/5] END loss=modified_huber, max_iter=5, penalty=l2;, score=0.582 total time=   0.0s\n",
      "[CV 4/5] END loss=modified_huber, max_iter=5, penalty=l2;, score=0.639 total time=   0.0s\n",
      "[CV 5/5] END loss=modified_huber, max_iter=5, penalty=l2;, score=0.707 total time=   0.0s\n",
      "[CV 1/5] END loss=modified_huber, max_iter=5, penalty=l1;, score=0.716 total time=   0.0s\n",
      "[CV 2/5] END loss=modified_huber, max_iter=5, penalty=l1;, score=0.634 total time=   0.0s\n",
      "[CV 3/5] END loss=modified_huber, max_iter=5, penalty=l1;, score=0.649 total time=   0.0s\n",
      "[CV 4/5] END loss=modified_huber, max_iter=5, penalty=l1;, score=0.632 total time=   0.0s\n",
      "[CV 5/5] END loss=modified_huber, max_iter=5, penalty=l1;, score=0.632 total time=   0.0s\n",
      "[CV 1/5] END loss=modified_huber, max_iter=5, penalty=elasticnet;, score=0.724 total time=   0.0s\n",
      "[CV 2/5] END loss=modified_huber, max_iter=5, penalty=elasticnet;, score=0.493 total time=   0.0s\n",
      "[CV 3/5] END loss=modified_huber, max_iter=5, penalty=elasticnet;, score=0.612 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END loss=modified_huber, max_iter=5, penalty=elasticnet;, score=0.729 total time=   0.0s\n",
      "[CV 5/5] END loss=modified_huber, max_iter=5, penalty=elasticnet;, score=0.414 total time=   0.0s\n",
      "[CV 1/5] END loss=modified_huber, max_iter=50, penalty=l2;, score=0.709 total time=   0.0s\n",
      "[CV 2/5] END loss=modified_huber, max_iter=50, penalty=l2;, score=0.694 total time=   0.0s\n",
      "[CV 3/5] END loss=modified_huber, max_iter=50, penalty=l2;, score=0.866 total time=   0.0s\n",
      "[CV 4/5] END loss=modified_huber, max_iter=50, penalty=l2;, score=0.677 total time=   0.0s\n",
      "[CV 5/5] END loss=modified_huber, max_iter=50, penalty=l2;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END loss=modified_huber, max_iter=50, penalty=l1;, score=0.366 total time=   0.0s\n",
      "[CV 2/5] END loss=modified_huber, max_iter=50, penalty=l1;, score=0.455 total time=   0.0s\n",
      "[CV 3/5] END loss=modified_huber, max_iter=50, penalty=l1;, score=0.687 total time=   0.0s\n",
      "[CV 4/5] END loss=modified_huber, max_iter=50, penalty=l1;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END loss=modified_huber, max_iter=50, penalty=l1;, score=0.767 total time=   0.0s\n",
      "[CV 1/5] END loss=modified_huber, max_iter=50, penalty=elasticnet;, score=0.634 total time=   0.0s\n",
      "[CV 2/5] END loss=modified_huber, max_iter=50, penalty=elasticnet;, score=0.687 total time=   0.0s\n",
      "[CV 3/5] END loss=modified_huber, max_iter=50, penalty=elasticnet;, score=0.746 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END loss=modified_huber, max_iter=50, penalty=elasticnet;, score=0.617 total time=   0.0s\n",
      "[CV 5/5] END loss=modified_huber, max_iter=50, penalty=elasticnet;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END loss=modified_huber, max_iter=100, penalty=l2;, score=0.701 total time=   0.0s\n",
      "[CV 2/5] END loss=modified_huber, max_iter=100, penalty=l2;, score=0.709 total time=   0.0s\n",
      "[CV 3/5] END loss=modified_huber, max_iter=100, penalty=l2;, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END loss=modified_huber, max_iter=100, penalty=l2;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END loss=modified_huber, max_iter=100, penalty=l2;, score=0.759 total time=   0.0s\n",
      "[CV 1/5] END loss=modified_huber, max_iter=100, penalty=l1;, score=0.754 total time=   0.0s\n",
      "[CV 2/5] END loss=modified_huber, max_iter=100, penalty=l1;, score=0.754 total time=   0.0s\n",
      "[CV 3/5] END loss=modified_huber, max_iter=100, penalty=l1;, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END loss=modified_huber, max_iter=100, penalty=l1;, score=0.774 total time=   0.0s\n",
      "[CV 5/5] END loss=modified_huber, max_iter=100, penalty=l1;, score=0.767 total time=   0.0s\n",
      "[CV 1/5] END loss=modified_huber, max_iter=100, penalty=elasticnet;, score=0.694 total time=   0.0s\n",
      "[CV 2/5] END loss=modified_huber, max_iter=100, penalty=elasticnet;, score=0.381 total time=   0.0s\n",
      "[CV 3/5] END loss=modified_huber, max_iter=100, penalty=elasticnet;, score=0.754 total time=   0.0s\n",
      "[CV 4/5] END loss=modified_huber, max_iter=100, penalty=elasticnet;, score=0.414 total time=   0.0s\n",
      "[CV 5/5] END loss=modified_huber, max_iter=100, penalty=elasticnet;, score=0.722 total time=   0.0s\n",
      "[CV 1/5] END loss=modified_huber, max_iter=500, penalty=l2;, score=0.687 total time=   0.0s\n",
      "[CV 2/5] END loss=modified_huber, max_iter=500, penalty=l2;, score=0.627 total time=   0.0s\n",
      "[CV 3/5] END loss=modified_huber, max_iter=500, penalty=l2;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END loss=modified_huber, max_iter=500, penalty=l2;, score=0.632 total time=   0.0s\n",
      "[CV 5/5] END loss=modified_huber, max_iter=500, penalty=l2;, score=0.654 total time=   0.0s\n",
      "[CV 1/5] END loss=modified_huber, max_iter=500, penalty=l1;, score=0.731 total time=   0.0s\n",
      "[CV 2/5] END loss=modified_huber, max_iter=500, penalty=l1;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END loss=modified_huber, max_iter=500, penalty=l1;, score=0.739 total time=   0.0s\n",
      "[CV 4/5] END loss=modified_huber, max_iter=500, penalty=l1;, score=0.789 total time=   0.0s\n",
      "[CV 5/5] END loss=modified_huber, max_iter=500, penalty=l1;, score=0.759 total time=   0.0s\n",
      "[CV 1/5] END loss=modified_huber, max_iter=500, penalty=elasticnet;, score=0.545 total time=   0.0s\n",
      "[CV 2/5] END loss=modified_huber, max_iter=500, penalty=elasticnet;, score=0.634 total time=   0.0s\n",
      "[CV 3/5] END loss=modified_huber, max_iter=500, penalty=elasticnet;, score=0.515 total time=   0.0s\n",
      "[CV 4/5] END loss=modified_huber, max_iter=500, penalty=elasticnet;, score=0.632 total time=   0.0s\n",
      "[CV 5/5] END loss=modified_huber, max_iter=500, penalty=elasticnet;, score=0.632 total time=   0.0s\n",
      "[CV 1/5] END loss=modified_huber, max_iter=1000, penalty=l2;, score=0.634 total time=   0.0s\n",
      "[CV 2/5] END loss=modified_huber, max_iter=1000, penalty=l2;, score=0.343 total time=   0.0s\n",
      "[CV 3/5] END loss=modified_huber, max_iter=1000, penalty=l2;, score=0.657 total time=   0.0s\n",
      "[CV 4/5] END loss=modified_huber, max_iter=1000, penalty=l2;, score=0.654 total time=   0.0s\n",
      "[CV 5/5] END loss=modified_huber, max_iter=1000, penalty=l2;, score=0.451 total time=   0.0s\n",
      "[CV 1/5] END loss=modified_huber, max_iter=1000, penalty=l1;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END loss=modified_huber, max_iter=1000, penalty=l1;, score=0.649 total time=   0.0s\n",
      "[CV 3/5] END loss=modified_huber, max_iter=1000, penalty=l1;, score=0.791 total time=   0.0s\n",
      "[CV 4/5] END loss=modified_huber, max_iter=1000, penalty=l1;, score=0.797 total time=   0.0s\n",
      "[CV 5/5] END loss=modified_huber, max_iter=1000, penalty=l1;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END loss=modified_huber, max_iter=1000, penalty=elasticnet;, score=0.701 total time=   0.0s\n",
      "[CV 2/5] END loss=modified_huber, max_iter=1000, penalty=elasticnet;, score=0.679 total time=   0.0s\n",
      "[CV 3/5] END loss=modified_huber, max_iter=1000, penalty=elasticnet;, score=0.851 total time=   0.0s\n",
      "[CV 4/5] END loss=modified_huber, max_iter=1000, penalty=elasticnet;, score=0.632 total time=   0.0s\n",
      "[CV 5/5] END loss=modified_huber, max_iter=1000, penalty=elasticnet;, score=0.632 total time=   0.0s\n",
      "[CV 1/5] END loss=squared_hinge, max_iter=5, penalty=l2;, score=0.657 total time=   0.0s\n",
      "[CV 2/5] END loss=squared_hinge, max_iter=5, penalty=l2;, score=0.709 total time=   0.0s\n",
      "[CV 3/5] END loss=squared_hinge, max_iter=5, penalty=l2;, score=0.627 total time=   0.0s\n",
      "[CV 4/5] END loss=squared_hinge, max_iter=5, penalty=l2;, score=0.368 total time=   0.0s\n",
      "[CV 5/5] END loss=squared_hinge, max_iter=5, penalty=l2;, score=0.632 total time=   0.0s\n",
      "[CV 1/5] END loss=squared_hinge, max_iter=5, penalty=l1;, score=0.724 total time=   0.0s\n",
      "[CV 2/5] END loss=squared_hinge, max_iter=5, penalty=l1;, score=0.701 total time=   0.0s\n",
      "[CV 3/5] END loss=squared_hinge, max_iter=5, penalty=l1;, score=0.716 total time=   0.0s\n",
      "[CV 4/5] END loss=squared_hinge, max_iter=5, penalty=l1;, score=0.624 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END loss=squared_hinge, max_iter=5, penalty=l1;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END loss=squared_hinge, max_iter=5, penalty=elasticnet;, score=0.687 total time=   0.0s\n",
      "[CV 2/5] END loss=squared_hinge, max_iter=5, penalty=elasticnet;, score=0.709 total time=   0.0s\n",
      "[CV 3/5] END loss=squared_hinge, max_iter=5, penalty=elasticnet;, score=0.575 total time=   0.0s\n",
      "[CV 4/5] END loss=squared_hinge, max_iter=5, penalty=elasticnet;, score=0.624 total time=   0.0s\n",
      "[CV 5/5] END loss=squared_hinge, max_iter=5, penalty=elasticnet;, score=0.692 total time=   0.0s\n",
      "[CV 1/5] END loss=squared_hinge, max_iter=50, penalty=l2;, score=0.687 total time=   0.0s\n",
      "[CV 2/5] END loss=squared_hinge, max_iter=50, penalty=l2;, score=0.701 total time=   0.0s\n",
      "[CV 3/5] END loss=squared_hinge, max_iter=50, penalty=l2;, score=0.627 total time=   0.0s\n",
      "[CV 4/5] END loss=squared_hinge, max_iter=50, penalty=l2;, score=0.714 total time=   0.0s\n",
      "[CV 5/5] END loss=squared_hinge, max_iter=50, penalty=l2;, score=0.669 total time=   0.0s\n",
      "[CV 1/5] END loss=squared_hinge, max_iter=50, penalty=l1;, score=0.731 total time=   0.0s\n",
      "[CV 2/5] END loss=squared_hinge, max_iter=50, penalty=l1;, score=0.746 total time=   0.0s\n",
      "[CV 3/5] END loss=squared_hinge, max_iter=50, penalty=l1;, score=0.649 total time=   0.0s\n",
      "[CV 4/5] END loss=squared_hinge, max_iter=50, penalty=l1;, score=0.774 total time=   0.0s\n",
      "[CV 5/5] END loss=squared_hinge, max_iter=50, penalty=l1;, score=0.707 total time=   0.0s\n",
      "[CV 1/5] END loss=squared_hinge, max_iter=50, penalty=elasticnet;, score=0.612 total time=   0.0s\n",
      "[CV 2/5] END loss=squared_hinge, max_iter=50, penalty=elasticnet;, score=0.366 total time=   0.0s\n",
      "[CV 3/5] END loss=squared_hinge, max_iter=50, penalty=elasticnet;, score=0.813 total time=   0.0s\n",
      "[CV 4/5] END loss=squared_hinge, max_iter=50, penalty=elasticnet;, score=0.677 total time=   0.0s\n",
      "[CV 5/5] END loss=squared_hinge, max_iter=50, penalty=elasticnet;, score=0.789 total time=   0.0s\n",
      "[CV 1/5] END loss=squared_hinge, max_iter=100, penalty=l2;, score=0.634 total time=   0.0s\n",
      "[CV 2/5] END loss=squared_hinge, max_iter=100, penalty=l2;, score=0.627 total time=   0.0s\n",
      "[CV 3/5] END loss=squared_hinge, max_iter=100, penalty=l2;, score=0.679 total time=   0.0s\n",
      "[CV 4/5] END loss=squared_hinge, max_iter=100, penalty=l2;, score=0.699 total time=   0.0s\n",
      "[CV 5/5] END loss=squared_hinge, max_iter=100, penalty=l2;, score=0.759 total time=   0.0s\n",
      "[CV 1/5] END loss=squared_hinge, max_iter=100, penalty=l1;, score=0.694 total time=   0.0s\n",
      "[CV 2/5] END loss=squared_hinge, max_iter=100, penalty=l1;, score=0.709 total time=   0.0s\n",
      "[CV 3/5] END loss=squared_hinge, max_iter=100, penalty=l1;, score=0.813 total time=   0.0s\n",
      "[CV 4/5] END loss=squared_hinge, max_iter=100, penalty=l1;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END loss=squared_hinge, max_iter=100, penalty=l1;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END loss=squared_hinge, max_iter=100, penalty=elasticnet;, score=0.701 total time=   0.0s\n",
      "[CV 2/5] END loss=squared_hinge, max_iter=100, penalty=elasticnet;, score=0.687 total time=   0.0s\n",
      "[CV 3/5] END loss=squared_hinge, max_iter=100, penalty=elasticnet;, score=0.739 total time=   0.0s\n",
      "[CV 4/5] END loss=squared_hinge, max_iter=100, penalty=elasticnet;, score=0.797 total time=   0.0s\n",
      "[CV 5/5] END loss=squared_hinge, max_iter=100, penalty=elasticnet;, score=0.729 total time=   0.0s\n",
      "[CV 1/5] END loss=squared_hinge, max_iter=500, penalty=l2;, score=0.746 total time=   0.0s\n",
      "[CV 2/5] END loss=squared_hinge, max_iter=500, penalty=l2;, score=0.694 total time=   0.0s\n",
      "[CV 3/5] END loss=squared_hinge, max_iter=500, penalty=l2;, score=0.754 total time=   0.0s\n",
      "[CV 4/5] END loss=squared_hinge, max_iter=500, penalty=l2;, score=0.699 total time=   0.0s\n",
      "[CV 5/5] END loss=squared_hinge, max_iter=500, penalty=l2;, score=0.436 total time=   0.0s\n",
      "[CV 1/5] END loss=squared_hinge, max_iter=500, penalty=l1;, score=0.724 total time=   0.0s\n",
      "[CV 2/5] END loss=squared_hinge, max_iter=500, penalty=l1;, score=0.388 total time=   0.0s\n",
      "[CV 3/5] END loss=squared_hinge, max_iter=500, penalty=l1;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END loss=squared_hinge, max_iter=500, penalty=l1;, score=0.639 total time=   0.0s\n",
      "[CV 5/5] END loss=squared_hinge, max_iter=500, penalty=l1;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END loss=squared_hinge, max_iter=500, penalty=elasticnet;, score=0.731 total time=   0.0s\n",
      "[CV 2/5] END loss=squared_hinge, max_iter=500, penalty=elasticnet;, score=0.627 total time=   0.0s\n",
      "[CV 3/5] END loss=squared_hinge, max_iter=500, penalty=elasticnet;, score=0.769 total time=   0.0s\n",
      "[CV 4/5] END loss=squared_hinge, max_iter=500, penalty=elasticnet;, score=0.692 total time=   0.0s\n",
      "[CV 5/5] END loss=squared_hinge, max_iter=500, penalty=elasticnet;, score=0.564 total time=   0.0s\n",
      "[CV 1/5] END loss=squared_hinge, max_iter=1000, penalty=l2;, score=0.396 total time=   0.0s\n",
      "[CV 2/5] END loss=squared_hinge, max_iter=1000, penalty=l2;, score=0.694 total time=   0.0s\n",
      "[CV 3/5] END loss=squared_hinge, max_iter=1000, penalty=l2;, score=0.373 total time=   0.0s\n",
      "[CV 4/5] END loss=squared_hinge, max_iter=1000, penalty=l2;, score=0.632 total time=   0.0s\n",
      "[CV 5/5] END loss=squared_hinge, max_iter=1000, penalty=l2;, score=0.368 total time=   0.0s\n",
      "[CV 1/5] END loss=squared_hinge, max_iter=1000, penalty=l1;, score=0.724 total time=   0.0s\n",
      "[CV 2/5] END loss=squared_hinge, max_iter=1000, penalty=l1;, score=0.672 total time=   0.0s\n",
      "[CV 3/5] END loss=squared_hinge, max_iter=1000, penalty=l1;, score=0.627 total time=   0.0s\n",
      "[CV 4/5] END loss=squared_hinge, max_iter=1000, penalty=l1;, score=0.789 total time=   0.0s\n",
      "[CV 5/5] END loss=squared_hinge, max_iter=1000, penalty=l1;, score=0.782 total time=   0.0s\n",
      "[CV 1/5] END loss=squared_hinge, max_iter=1000, penalty=elasticnet;, score=0.388 total time=   0.0s\n",
      "[CV 2/5] END loss=squared_hinge, max_iter=1000, penalty=elasticnet;, score=0.388 total time=   0.0s\n",
      "[CV 3/5] END loss=squared_hinge, max_iter=1000, penalty=elasticnet;, score=0.664 total time=   0.0s\n",
      "[CV 4/5] END loss=squared_hinge, max_iter=1000, penalty=elasticnet;, score=0.444 total time=   0.0s\n",
      "[CV 5/5] END loss=squared_hinge, max_iter=1000, penalty=elasticnet;, score=0.376 total time=   0.0s\n",
      "[CV 1/5] END loss=perceptron, max_iter=5, penalty=l2;, score=0.687 total time=   0.0s\n",
      "[CV 2/5] END loss=perceptron, max_iter=5, penalty=l2;, score=0.627 total time=   0.0s\n",
      "[CV 3/5] END loss=perceptron, max_iter=5, penalty=l2;, score=0.627 total time=   0.0s\n",
      "[CV 4/5] END loss=perceptron, max_iter=5, penalty=l2;, score=0.632 total time=   0.0s\n",
      "[CV 5/5] END loss=perceptron, max_iter=5, penalty=l2;, score=0.632 total time=   0.0s\n",
      "[CV 1/5] END loss=perceptron, max_iter=5, penalty=l1;, score=0.396 total time=   0.0s\n",
      "[CV 2/5] END loss=perceptron, max_iter=5, penalty=l1;, score=0.687 total time=   0.0s\n",
      "[CV 3/5] END loss=perceptron, max_iter=5, penalty=l1;, score=0.739 total time=   0.0s\n",
      "[CV 4/5] END loss=perceptron, max_iter=5, penalty=l1;, score=0.662 total time=   0.0s\n",
      "[CV 5/5] END loss=perceptron, max_iter=5, penalty=l1;, score=0.632 total time=   0.0s\n",
      "[CV 1/5] END loss=perceptron, max_iter=5, penalty=elasticnet;, score=0.634 total time=   0.0s\n",
      "[CV 2/5] END loss=perceptron, max_iter=5, penalty=elasticnet;, score=0.649 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END loss=perceptron, max_iter=5, penalty=elasticnet;, score=0.627 total time=   0.0s\n",
      "[CV 4/5] END loss=perceptron, max_iter=5, penalty=elasticnet;, score=0.383 total time=   0.0s\n",
      "[CV 5/5] END loss=perceptron, max_iter=5, penalty=elasticnet;, score=0.376 total time=   0.0s\n",
      "[CV 1/5] END loss=perceptron, max_iter=50, penalty=l2;, score=0.701 total time=   0.0s\n",
      "[CV 2/5] END loss=perceptron, max_iter=50, penalty=l2;, score=0.612 total time=   0.0s\n",
      "[CV 3/5] END loss=perceptron, max_iter=50, penalty=l2;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END loss=perceptron, max_iter=50, penalty=l2;, score=0.624 total time=   0.0s\n",
      "[CV 5/5] END loss=perceptron, max_iter=50, penalty=l2;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END loss=perceptron, max_iter=50, penalty=l1;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END loss=perceptron, max_iter=50, penalty=l1;, score=0.716 total time=   0.0s\n",
      "[CV 3/5] END loss=perceptron, max_iter=50, penalty=l1;, score=0.687 total time=   0.0s\n",
      "[CV 4/5] END loss=perceptron, max_iter=50, penalty=l1;, score=0.707 total time=   0.0s\n",
      "[CV 5/5] END loss=perceptron, max_iter=50, penalty=l1;, score=0.774 total time=   0.0s\n",
      "[CV 1/5] END loss=perceptron, max_iter=50, penalty=elasticnet;, score=0.709 total time=   0.0s\n",
      "[CV 2/5] END loss=perceptron, max_iter=50, penalty=elasticnet;, score=0.716 total time=   0.0s\n",
      "[CV 3/5] END loss=perceptron, max_iter=50, penalty=elasticnet;, score=0.418 total time=   0.0s\n",
      "[CV 4/5] END loss=perceptron, max_iter=50, penalty=elasticnet;, score=0.511 total time=   0.0s\n",
      "[CV 5/5] END loss=perceptron, max_iter=50, penalty=elasticnet;, score=0.714 total time=   0.0s\n",
      "[CV 1/5] END loss=perceptron, max_iter=100, penalty=l2;, score=0.754 total time=   0.0s\n",
      "[CV 2/5] END loss=perceptron, max_iter=100, penalty=l2;, score=0.709 total time=   0.0s\n",
      "[CV 3/5] END loss=perceptron, max_iter=100, penalty=l2;, score=0.687 total time=   0.0s\n",
      "[CV 4/5] END loss=perceptron, max_iter=100, penalty=l2;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END loss=perceptron, max_iter=100, penalty=l2;, score=0.654 total time=   0.0s\n",
      "[CV 1/5] END loss=perceptron, max_iter=100, penalty=l1;, score=0.396 total time=   0.0s\n",
      "[CV 2/5] END loss=perceptron, max_iter=100, penalty=l1;, score=0.627 total time=   0.0s\n",
      "[CV 3/5] END loss=perceptron, max_iter=100, penalty=l1;, score=0.836 total time=   0.0s\n",
      "[CV 4/5] END loss=perceptron, max_iter=100, penalty=l1;, score=0.805 total time=   0.0s\n",
      "[CV 5/5] END loss=perceptron, max_iter=100, penalty=l1;, score=0.737 total time=   0.0s\n",
      "[CV 1/5] END loss=perceptron, max_iter=100, penalty=elasticnet;, score=0.701 total time=   0.0s\n",
      "[CV 2/5] END loss=perceptron, max_iter=100, penalty=elasticnet;, score=0.358 total time=   0.0s\n",
      "[CV 3/5] END loss=perceptron, max_iter=100, penalty=elasticnet;, score=0.776 total time=   0.0s\n",
      "[CV 4/5] END loss=perceptron, max_iter=100, penalty=elasticnet;, score=0.744 total time=   0.0s\n",
      "[CV 5/5] END loss=perceptron, max_iter=100, penalty=elasticnet;, score=0.729 total time=   0.0s\n",
      "[CV 1/5] END loss=perceptron, max_iter=500, penalty=l2;, score=0.634 total time=   0.0s\n",
      "[CV 2/5] END loss=perceptron, max_iter=500, penalty=l2;, score=0.701 total time=   0.0s\n",
      "[CV 3/5] END loss=perceptron, max_iter=500, penalty=l2;, score=0.701 total time=   0.0s\n",
      "[CV 4/5] END loss=perceptron, max_iter=500, penalty=l2;, score=0.729 total time=   0.0s\n",
      "[CV 5/5] END loss=perceptron, max_iter=500, penalty=l2;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END loss=perceptron, max_iter=500, penalty=l1;, score=0.627 total time=   0.0s\n",
      "[CV 2/5] END loss=perceptron, max_iter=500, penalty=l1;, score=0.642 total time=   0.0s\n",
      "[CV 3/5] END loss=perceptron, max_iter=500, penalty=l1;, score=0.873 total time=   0.0s\n",
      "[CV 4/5] END loss=perceptron, max_iter=500, penalty=l1;, score=0.459 total time=   0.0s\n",
      "[CV 5/5] END loss=perceptron, max_iter=500, penalty=l1;, score=0.782 total time=   0.0s\n",
      "[CV 1/5] END loss=perceptron, max_iter=500, penalty=elasticnet;, score=0.746 total time=   0.0s\n",
      "[CV 2/5] END loss=perceptron, max_iter=500, penalty=elasticnet;, score=0.388 total time=   0.0s\n",
      "[CV 3/5] END loss=perceptron, max_iter=500, penalty=elasticnet;, score=0.828 total time=   0.0s\n",
      "[CV 4/5] END loss=perceptron, max_iter=500, penalty=elasticnet;, score=0.639 total time=   0.0s\n",
      "[CV 5/5] END loss=perceptron, max_iter=500, penalty=elasticnet;, score=0.767 total time=   0.0s\n",
      "[CV 1/5] END loss=perceptron, max_iter=1000, penalty=l2;, score=0.418 total time=   0.0s\n",
      "[CV 2/5] END loss=perceptron, max_iter=1000, penalty=l2;, score=0.746 total time=   0.0s\n",
      "[CV 3/5] END loss=perceptron, max_iter=1000, penalty=l2;, score=0.866 total time=   0.0s\n",
      "[CV 4/5] END loss=perceptron, max_iter=1000, penalty=l2;, score=0.699 total time=   0.0s\n",
      "[CV 5/5] END loss=perceptron, max_iter=1000, penalty=l2;, score=0.737 total time=   0.0s\n",
      "[CV 1/5] END loss=perceptron, max_iter=1000, penalty=l1;, score=0.746 total time=   0.0s\n",
      "[CV 2/5] END loss=perceptron, max_iter=1000, penalty=l1;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END loss=perceptron, max_iter=1000, penalty=l1;, score=0.664 total time=   0.0s\n",
      "[CV 4/5] END loss=perceptron, max_iter=1000, penalty=l1;, score=0.609 total time=   0.0s\n",
      "[CV 5/5] END loss=perceptron, max_iter=1000, penalty=l1;, score=0.729 total time=   0.0s\n",
      "[CV 1/5] END loss=perceptron, max_iter=1000, penalty=elasticnet;, score=0.716 total time=   0.0s\n",
      "[CV 2/5] END loss=perceptron, max_iter=1000, penalty=elasticnet;, score=0.381 total time=   0.0s\n",
      "[CV 3/5] END loss=perceptron, max_iter=1000, penalty=elasticnet;, score=0.806 total time=   0.0s\n",
      "[CV 4/5] END loss=perceptron, max_iter=1000, penalty=elasticnet;, score=0.714 total time=   0.0s\n",
      "[CV 5/5] END loss=perceptron, max_iter=1000, penalty=elasticnet;, score=0.632 total time=   0.0s\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV 1/5] END ......criterion=gini, max_depth=10;, score=0.769 total time=   0.0s\n",
      "[CV 2/5] END ......criterion=gini, max_depth=10;, score=0.746 total time=   0.0s\n",
      "[CV 3/5] END ......criterion=gini, max_depth=10;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END ......criterion=gini, max_depth=10;, score=0.767 total time=   0.0s\n",
      "[CV 5/5] END ......criterion=gini, max_depth=10;, score=0.782 total time=   0.0s\n",
      "[CV 1/5] END ......criterion=gini, max_depth=20;, score=0.731 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "75 fits failed out of a total of 450.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 890, in fit\n",
      "    return self._fit(\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 658, in _fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 161, in _validate_params\n",
      "    raise ValueError(\"The loss %s is not supported. \" % self.loss)\n",
      "ValueError: The loss loss is not supported. \n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.62275839 0.69013579 0.65423634 0.6330266  0.73049041 0.70357985\n",
      " 0.65888228 0.72905398 0.71853888 0.69757603 0.67029514 0.73354281\n",
      " 0.65278869 0.61126697 0.68120301 0.62278083 0.55942094 0.66633374\n",
      " 0.68115812 0.73646055 0.6843003  0.70963977 0.61697901 0.72299405\n",
      " 0.66901582 0.76343845 0.59670071 0.74244193 0.75003928 0.65861295\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.60947144 0.65263158 0.59424307\n",
      " 0.74395691 0.6067557  0.69162832 0.76647963 0.78588262 0.59273931\n",
      " 0.67953092 0.75156548 0.59143755 0.5479183  0.73667377 0.69890024\n",
      " 0.59850746 0.70805746 0.65718775 0.6796768  0.72161374 0.65144204\n",
      " 0.67978902 0.75907306 0.73063629 0.66587364 0.66479632 0.67650095\n",
      " 0.49253731 0.71876333 0.45196948 0.64069128 0.62282572 0.53396925\n",
      " 0.70208731 0.71116597 0.6137695  0.71255751 0.67991247 0.66190102\n",
      " 0.71272584 0.67647851 0.67374032 0.69318819 0.69751992 0.64976995]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ......criterion=gini, max_depth=20;, score=0.769 total time=   0.0s\n",
      "[CV 3/5] END ......criterion=gini, max_depth=20;, score=0.828 total time=   0.0s\n",
      "[CV 4/5] END ......criterion=gini, max_depth=20;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END ......criterion=gini, max_depth=20;, score=0.752 total time=   0.0s\n",
      "[CV 1/5] END ......criterion=gini, max_depth=30;, score=0.761 total time=   0.0s\n",
      "[CV 2/5] END ......criterion=gini, max_depth=30;, score=0.784 total time=   0.0s\n",
      "[CV 3/5] END ......criterion=gini, max_depth=30;, score=0.828 total time=   0.0s\n",
      "[CV 4/5] END ......criterion=gini, max_depth=30;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END ......criterion=gini, max_depth=30;, score=0.759 total time=   0.0s\n",
      "[CV 1/5] END ......criterion=gini, max_depth=40;, score=0.746 total time=   0.0s\n",
      "[CV 2/5] END ......criterion=gini, max_depth=40;, score=0.776 total time=   0.0s\n",
      "[CV 3/5] END ......criterion=gini, max_depth=40;, score=0.836 total time=   0.0s\n",
      "[CV 4/5] END ......criterion=gini, max_depth=40;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END ......criterion=gini, max_depth=40;, score=0.759 total time=   0.0s\n",
      "[CV 1/5] END ......criterion=gini, max_depth=50;, score=0.769 total time=   0.0s\n",
      "[CV 2/5] END ......criterion=gini, max_depth=50;, score=0.784 total time=   0.0s\n",
      "[CV 3/5] END ......criterion=gini, max_depth=50;, score=0.813 total time=   0.0s\n",
      "[CV 4/5] END ......criterion=gini, max_depth=50;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END ......criterion=gini, max_depth=50;, score=0.744 total time=   0.0s\n",
      "[CV 1/5] END ...criterion=entropy, max_depth=10;, score=0.821 total time=   0.0s\n",
      "[CV 2/5] END ...criterion=entropy, max_depth=10;, score=0.746 total time=   0.0s\n",
      "[CV 3/5] END ...criterion=entropy, max_depth=10;, score=0.851 total time=   0.0s\n",
      "[CV 4/5] END ...criterion=entropy, max_depth=10;, score=0.767 total time=   0.0s\n",
      "[CV 5/5] END ...criterion=entropy, max_depth=10;, score=0.812 total time=   0.0s\n",
      "[CV 1/5] END ...criterion=entropy, max_depth=20;, score=0.776 total time=   0.0s\n",
      "[CV 2/5] END ...criterion=entropy, max_depth=20;, score=0.769 total time=   0.0s\n",
      "[CV 3/5] END ...criterion=entropy, max_depth=20;, score=0.828 total time=   0.0s\n",
      "[CV 4/5] END ...criterion=entropy, max_depth=20;, score=0.774 total time=   0.0s\n",
      "[CV 5/5] END ...criterion=entropy, max_depth=20;, score=0.812 total time=   0.0s\n",
      "[CV 1/5] END ...criterion=entropy, max_depth=30;, score=0.776 total time=   0.0s\n",
      "[CV 2/5] END ...criterion=entropy, max_depth=30;, score=0.746 total time=   0.0s\n",
      "[CV 3/5] END ...criterion=entropy, max_depth=30;, score=0.836 total time=   0.0s\n",
      "[CV 4/5] END ...criterion=entropy, max_depth=30;, score=0.774 total time=   0.0s\n",
      "[CV 5/5] END ...criterion=entropy, max_depth=30;, score=0.805 total time=   0.0s\n",
      "[CV 1/5] END ...criterion=entropy, max_depth=40;, score=0.776 total time=   0.0s\n",
      "[CV 2/5] END ...criterion=entropy, max_depth=40;, score=0.746 total time=   0.0s\n",
      "[CV 3/5] END ...criterion=entropy, max_depth=40;, score=0.843 total time=   0.0s\n",
      "[CV 4/5] END ...criterion=entropy, max_depth=40;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END ...criterion=entropy, max_depth=40;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END ...criterion=entropy, max_depth=50;, score=0.761 total time=   0.0s\n",
      "[CV 2/5] END ...criterion=entropy, max_depth=50;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END ...criterion=entropy, max_depth=50;, score=0.828 total time=   0.0s\n",
      "[CV 4/5] END ...criterion=entropy, max_depth=50;, score=0.767 total time=   0.0s\n",
      "[CV 5/5] END ...criterion=entropy, max_depth=50;, score=0.805 total time=   0.0s\n",
      "[CV 1/5] END ..criterion=log_loss, max_depth=10;, score=0.836 total time=   0.0s\n",
      "[CV 2/5] END ..criterion=log_loss, max_depth=10;, score=0.746 total time=   0.0s\n",
      "[CV 3/5] END ..criterion=log_loss, max_depth=10;, score=0.843 total time=   0.0s\n",
      "[CV 4/5] END ..criterion=log_loss, max_depth=10;, score=0.782 total time=   0.0s\n",
      "[CV 5/5] END ..criterion=log_loss, max_depth=10;, score=0.805 total time=   0.0s\n",
      "[CV 1/5] END ..criterion=log_loss, max_depth=20;, score=0.769 total time=   0.0s\n",
      "[CV 2/5] END ..criterion=log_loss, max_depth=20;, score=0.761 total time=   0.0s\n",
      "[CV 3/5] END ..criterion=log_loss, max_depth=20;, score=0.828 total time=   0.0s\n",
      "[CV 4/5] END ..criterion=log_loss, max_depth=20;, score=0.774 total time=   0.0s\n",
      "[CV 5/5] END ..criterion=log_loss, max_depth=20;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END ..criterion=log_loss, max_depth=30;, score=0.769 total time=   0.0s\n",
      "[CV 2/5] END ..criterion=log_loss, max_depth=30;, score=0.754 total time=   0.0s\n",
      "[CV 3/5] END ..criterion=log_loss, max_depth=30;, score=0.836 total time=   0.0s\n",
      "[CV 4/5] END ..criterion=log_loss, max_depth=30;, score=0.789 total time=   0.0s\n",
      "[CV 5/5] END ..criterion=log_loss, max_depth=30;, score=0.812 total time=   0.0s\n",
      "[CV 1/5] END ..criterion=log_loss, max_depth=40;, score=0.761 total time=   0.0s\n",
      "[CV 2/5] END ..criterion=log_loss, max_depth=40;, score=0.761 total time=   0.0s\n",
      "[CV 3/5] END ..criterion=log_loss, max_depth=40;, score=0.843 total time=   0.0s\n",
      "[CV 4/5] END ..criterion=log_loss, max_depth=40;, score=0.744 total time=   0.0s\n",
      "[CV 5/5] END ..criterion=log_loss, max_depth=40;, score=0.812 total time=   0.0s\n",
      "[CV 1/5] END ..criterion=log_loss, max_depth=50;, score=0.769 total time=   0.0s\n",
      "[CV 2/5] END ..criterion=log_loss, max_depth=50;, score=0.724 total time=   0.0s\n",
      "[CV 3/5] END ..criterion=log_loss, max_depth=50;, score=0.836 total time=   0.0s\n",
      "[CV 4/5] END ..criterion=log_loss, max_depth=50;, score=0.774 total time=   0.0s\n",
      "[CV 5/5] END ..criterion=log_loss, max_depth=50;, score=0.812 total time=   0.0s\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{'penalty':['l1','l2','elasticnet','none'], \n",
    "               'max_iter':[100,500,1000], \n",
    "               'solver':['newton-cg','lbfgs','liblinear','sag','saga']},\n",
    "             {'criterion':['gini','entropy','log_loss'], \n",
    "              'min_samples_split':[2,4,8]},\n",
    "             {'C': [0.1,1, 10, 100, 1000], \n",
    "              'gamma': [1,0.1,0.01,0.001,0.0001], \n",
    "              'kernel': ['rbf']},\n",
    "             {'loss':['hinge','log_loss','loss','modified_huber','squared_hinge','perceptron'], \n",
    "              'penalty':['l2','l1','elasticnet'], \n",
    "              'max_iter':[5,50,100,500,1000]},\n",
    "             {'max_depth':[10,20,30,40,50],\n",
    "              'criterion':['gini','entropy','log_loss']}]\n",
    "\n",
    "model = [LogisticRegression(), RandomForestClassifier(), SVC(), SGDClassifier(), DecisionTreeClassifier()]\n",
    "abrv = ['lr','rf','svc','sgd','dt']\n",
    "best_params=[]\n",
    "best_estimator=[]\n",
    "\n",
    "for a, m, param_grid in zip(abrv, model, param_grid):\n",
    "    grid = GridSearchCV(m,param_grid,refit=True,verbose=3)\n",
    "    grid.fit(X_train, y_train.values.ravel())\n",
    "    best_params.append(grid.best_params_)\n",
    "    best_estimator.append(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "bfe61027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : LR\n",
      "                        Best Parameter : {'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "                        Best Estimator : LogisticRegression(solver='liblinear') \n",
      "\n",
      "Model : RF\n",
      "                        Best Parameter : {'criterion': 'gini', 'min_samples_split': 4}\n",
      "                        Best Estimator : RandomForestClassifier(min_samples_split=4) \n",
      "\n",
      "Model : SVC\n",
      "                        Best Parameter : {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "                        Best Estimator : SVC(C=1000, gamma=0.0001) \n",
      "\n",
      "Model : SGD\n",
      "                        Best Parameter : {'loss': 'modified_huber', 'max_iter': 100, 'penalty': 'l1'}\n",
      "                        Best Estimator : SGDClassifier(loss='modified_huber', max_iter=100, penalty='l1') \n",
      "\n",
      "Model : DT\n",
      "                        Best Parameter : {'criterion': 'log_loss', 'max_depth': 10}\n",
      "                        Best Estimator : DecisionTreeClassifier(criterion='log_loss', max_depth=10) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for a, p, e in zip(abrv,best_params,best_estimator):\n",
    "    print(f\"\"\"Model : {a.upper()}\n",
    "                        Best Parameter : {p}\n",
    "                        Best Estimator : {e} \\n\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "1524c313",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_lr = LogisticRegression(max_iter= 100, penalty = 'l2', solver = 'liblinear', random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "82c64499",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf_lr = best_model_lr.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "3923289d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "61191df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_rf = RandomForestClassifier(criterion= 'log_loss', min_samples_split = 8, random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "963cd0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf_rf = best_model_rf.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "768f235e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "70b9a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_sgd = SGDClassifier(loss= 'hinge', max_iter = 100, penalty = 'l1', random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "26833498",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf_sgd = best_model_sgd.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "9ca0e01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf_sgd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "142588f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['Survived'] = best_clf_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "7280b471",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['Survived'] = best_clf_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "19ff328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['Survived'] = best_clf_sgd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "5cd00666",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[['PassengerId', 'Survived']].to_csv('rf_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "1bc92285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User\\\\Downloads\\\\kaggle'"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "b6d6991a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Linear_Prediction</th>\n",
       "      <th>RF_prediction</th>\n",
       "      <th>SGD_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>34.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>62.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>38.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass  Sex       Age  SibSp  Parch      Fare  Embarked  \\\n",
       "0            892       3    1  34.50000      0      0    7.8292         1   \n",
       "1            893       3    0  47.00000      1      0    7.0000         2   \n",
       "2            894       2    1  62.00000      0      0    9.6875         1   \n",
       "3            895       3    1  27.00000      0      0    8.6625         2   \n",
       "4            896       3    0  22.00000      1      1   12.2875         2   \n",
       "..           ...     ...  ...       ...    ...    ...       ...       ...   \n",
       "413         1305       3    1  30.27259      0      0    8.0500         2   \n",
       "414         1306       1    0  39.00000      0      0  108.9000         0   \n",
       "415         1307       3    1  38.50000      0      0    7.2500         2   \n",
       "416         1308       3    1  30.27259      0      0    8.0500         2   \n",
       "417         1309       3    1  30.27259      1      1   22.3583         0   \n",
       "\n",
       "     Linear_Prediction  RF_prediction  SGD_prediction  \n",
       "0                    0              0               0  \n",
       "1                    0              0               1  \n",
       "2                    0              0               0  \n",
       "3                    0              0               0  \n",
       "4                    1              0               1  \n",
       "..                 ...            ...             ...  \n",
       "413                  0              0               0  \n",
       "414                  1              1               1  \n",
       "415                  0              0               0  \n",
       "416                  0              0               0  \n",
       "417                  0              0               0  \n",
       "\n",
       "[418 rows x 11 columns]"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.drop('Survived', axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16243c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
